
### **Camera Intrinsics: Overview**

When you take a picture with a camera, the 3D world (objects, scenes) needs to be projected onto a 2D image plane (the image sensor or film). **Camera intrinsics** describe the internal characteristics of the camera that affect how the 3D world gets transformed into a 2D image. These include:

* The **sensor size** and its resolution.
* The **focal length** of the lens.
* The **sensor orientation** and **scaling factors**.

After projecting a 3D point onto an image plane, we must adjust the coordinates to match the actual sensor's pixel layout and its positioning in space relative to the cameraâ€™s origin.

### **Step-by-Step Breakdown of Equations**

#### **Step 1: Projection of 3D Points to 2D Pixels**

We start with a **3D point $p$** in space and want to map it to a **2D point** on the image plane (i.e., a pixel coordinate).

* $\mathbf{p}$ is the **3D point** in the camera's coordinate system.
* $\mathbf{x_s}$ is the **2D pixel coordinate** on the image sensor.

The projection can be written as:

$$
p = M_s \mathbf{x_s}
$$

Where:

* $M_s$ is a **sensor homography** (a transformation matrix) that includes sensor parameters (rotation, scaling).
* $\mathbf{x_s} = \begin{bmatrix} x_s \\ y_s \\ 1 \end{bmatrix}$ is a **homogeneous coordinate** for the 2D pixel position.

This transformation can be broken down into:

1. **Scaling by Pixel Spacing**: First, we scale the pixel coordinates by the sensor's pixel spacing in the $x$ and $y$ directions, denoted $s_x$ and $s_y$, which are usually given in microns for solid-state sensors.

2. **Rotation and Translation**: The sensor's orientation and position in space are described by a rotation matrix $R_s$ and a translation vector $c_s$.

Thus, the combined projection equation is:

$$
\mathbf{p} = 
\begin{bmatrix}
R_s & c_s
\end{bmatrix}
\begin{bmatrix}
s_x & 0 & 0 \\
0 & s_y & 0 \\
0 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
x_s \\
y_s \\
1
\end{bmatrix}
$$

This matrix equation takes the **2D pixel coordinates** $(x_s, y_s)$ and transforms them to a **3D point** $p$.

#### **Step 2: Relating to Camera Intrinsics**

The final **2D image coordinates** are often represented as:

$$
\tilde{x}_s = \alpha M_s^{-1} \mathbf{p_c} = K \mathbf{p_c}
$$

Where:

* $\tilde{x}_s$ is the 2D pixel coordinates after projection.
* $\mathbf{p_c}$ is the 3D camera-centered point.
* $K$ is the **intrinsic camera matrix**.
* $M_s^{-1}$ represents the inverse of the sensor matrix.

The intrinsic camera matrix $K$ typically looks like this:

$$
K =
\begin{bmatrix}
f_x & s & c_x \\
0 & f_y & c_y \\
0 & 0 & 1
\end{bmatrix}
$$

Where:

* $f_x$ and $f_y$ are the **focal lengths** in the $x$ and $y$ directions.
* $s$ is the **skew factor**, representing the non-perpendicularity of the axes.
* $c_x$ and $c_y$ are the **coordinates of the image center** (often at the center of the image).

#### **Step 3: Degrees of Freedom in Camera Calibration**

The matrix $K$ has **seven degrees of freedom**:

* **Focal length** (2 parameters: $f_x$, $f_y$).
* **Image center** (2 parameters: $c_x$, $c_y$).
* **Skew** (1 parameter: $s$).
* **Sensor scaling** (2 parameters: $s_x$, $s_y$).

In practice, the **skew** is often neglected (set to 0), and the **aspect ratio** between the $x$ and $y$-scales is assumed to be 1, simplifying the matrix to:

$$
K =
\begin{bmatrix}
f & 0 & c_x \\
0 & f & c_y \\
0 & 0 & 1
\end{bmatrix}
$$

Where $f$ is the focal length and $c_x, c_y$ are the image center coordinates.

#### **Step 4: Calibration with the Camera Matrix**

The camera matrix $P$ combines both the intrinsic matrix $K$ and the extrinsic parameters (rotation $R$ and translation $t$):

$$
P = K [R | t]
$$

This matrix maps the **3D world coordinates** to **2D image coordinates**.

#### **Simplified Camera Model**

A simplified model often assumes that the image center is at the center of the image (i.e., $c_x = W/2$ and $c_y = H/2$ for an image with width $W$ and height $H$):

$$
K = 
\begin{bmatrix}
f & 0 & W/2 \\
0 & f & H/2 \\
0 & 0 & 1
\end{bmatrix}
$$

This is a simplified but commonly used camera intrinsics model.

---

### **Summary of Key Concepts**

1. **Camera intrinsics** involve the internal parameters of the camera, such as focal length, image center, and pixel spacing.
2. The **intrinsic matrix $K$** maps 3D points (in the camera's coordinate system) to 2D pixel coordinates.
3. Calibration of a camera requires determining these parameters, which is typically done using a series of images and known 3D world points.
4. The **focal length** determines the camera's zoom level, and the **image center** represents where the camera's optical center intersects the image plane.
5. **Skew** is generally neglected, and an aspect ratio of 1 is often assumed for simplicity.



