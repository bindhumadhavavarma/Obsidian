
# what problem are we solving?

we want a new image **g** made from an old image **f** by looking at small neighborhoods around every pixel and combining them with fixed weights (a tiny stencil). that’s “linear filtering”.

# the cast of characters (symbols)

* **f(i, j)**: input image value at row **i**, column **j**
* **g(i, j)**: output image value at row **i**, column **j**
* **h(k, l)**: the **kernel / mask / filter** weights (a small matrix like 3×3, 5×5, …)
* **N**: the neighborhood (the set of offsets **(k, l)** the kernel covers, e.g., k,l ∈ {−1,0,1} for a 3×3)

think of **h** as a rubber stamp with numbers on it. we place its center over each pixel of **f**, multiply, sum, and write the result into **g** at the same location.

---

# step 1 — correlation (often called “filtering” in practice)

**idea:** slide **h** across **f** without flipping **h**.

**rule:**
g(i, j) = Σₖ,ₗ f(i + k, j + l) · h(k, l)  (“correlation”)

**read it:** for output pixel (i, j),

1. align the kernel center on (i, j),
2. for each kernel cell (k, l), pick the input pixel **f(i+k, j+l)** under it,
3. multiply by the weight **h(k, l)**,
4. sum all products → that’s **g(i, j)**.

**notation shortcut:** g = f ⊗ h (⊗ for correlation)

> most image libraries’ “filter2D” operations are this correlation rule. deep-learning “conv2d” layers also use correlation (no flip) but historically call it “convolution”.

---

# step 2 — convolution (the only difference is a flip)

**idea:** same sliding, but first rotate the kernel 180° (flip in both x and y).

**rule:**
g(i, j) = Σₖ,ₗ f(i − k, j − l) · h(k, l)  (“convolution”)
equivalently, g = f \* h ( \* for convolution)

**why this definition? (impulse response intuition)**

* let δ(i, j) be an image that’s 0 everywhere except a single 1 at the origin (an “impulse”).
* **convolution** with δ reproduces **h** exactly: h \* δ = h (nice: the kernel shows up unflipped).
* **correlation** with δ gives the **reflected** h (because correlation doesn’t flip the kernel, so the reflection happens in the math).

**practical takeaway / mnemonic:**

* **correlation**: slide & sum (no flip)
* **convolution**: **flip**, then slide & sum

in many image-processing tasks, the flip doesn’t change the effect when **h** is symmetric (e.g., a Gaussian blur), so people use the words loosely.

---

# step 3 — a tiny concrete example

**image patch (3×3 around the target pixel):**

```
f = [ [10, 20, 10],
      [20, 40, 20],
      [10, 20, 10] ]
```

**box-blur kernel h (3×3, normalized):**

```
h = (1/9) * [ [1,1,1],
              [1,1,1],
              [1,1,1] ]
```

**correlation at center pixel:** multiply each pair and sum:
(10+20+10 + 20+40+20 + 10+20+10) \* (1/9) = 180/9 = 20 → g(center)=20.
convolution gives the same here because **h** is symmetric.

---

# step 4 — what “linear” and “shift-invariant” mean (LSI)

both correlation and convolution (with a **fixed** kernel) are **linear shift-invariant (LSI)**:

**linear:** filtering(f₀ + f₁) = filtering(f₀) + filtering(f₁)
**shift-invariant:** if you shift the input, the output shifts the same way; the operator behaves the same everywhere (same kernel for all pixels).

that’s exactly what equations (3.16) and (3.17) say.

---

# step 5 — spatially varying kernels (not shift-invariant)

sometimes the kernel itself changes with position, e.g., h(k, l; i, j). then

```
g(i, j) = Σₖ,ₗ f(i − k, j − l) · h(k, l; i, j)
```

this models effects like defocus blur that varies with depth across the image. it’s no longer shift-invariant because the rule depends on (i, j).

---

# step 6 — the matrix view (why fig. 3.12 shows a banded matrix)

you can “unroll” the image into a long vector **f** and write filtering as a sparse matrix **H**:

g = H f

in 1D, convolving with h = \[¼, ½, ¼] produces a **tridiagonal Toeplitz** matrix (the same three weights repeated along diagonals). in 2D, you get a big sparse **block-Toeplitz with Toeplitz blocks** (BTTB). this viewpoint is handy for proofs and for connecting to linear algebra and Fourier analysis.

---

# step 7 — why we care about convolution mathematically

* **commutative:** f \* h = h \* f
* **associative:** (f \* h₁) \* h₂ = f \* (h₁ \* h₂)
* **Fourier magic:** 𝓕{f \* h} = 𝓕{f} · 𝓕{h} (convolution in space = multiplication in frequency).
  this is why we can do fast filtering via FFTs for large kernels.

---

# step 8 — practical bits you’ll hit in code

* **boundary handling:** when the kernel spills off the edge, choose a rule: zero-pad, reflect, clamp, wrap. this changes edge appearance.
* **normalization:** for blurs, make weights sum to 1 so brightness stays similar.
* **sharpening / edges:** kernels with positive center and negative neighbors (e.g., Laplacian, Sobel) enhance edges or detect them.
* **library conventions:**

  * OpenCV’s `filter2D`, SciPy’s `correlate2d`, PyTorch/TF “conv” layers → **correlation** by default (no flip).
  * If you truly need mathematical convolution, flip the kernel yourself (rotate 180°) before calling.

---

## TL;DR

* **Filtering** = sliding a small weight matrix over the image, multiply-accumulate → new pixel.
* **Correlation** = slide & sum (no flip).
* **Convolution** = **flip** the kernel, then slide & sum.
* Both are **linear** and **shift-invariant** when the kernel is fixed.
* Convolution plays beautifully with the Fourier transform (space-domain convolution ↔ frequency-domain multiplication).


---

## 🔹 Step 1: Cost of a normal 2D convolution

Suppose you have a **K×K kernel** (say 5×5).

* For each output pixel, you multiply-add **K² numbers**.

  * Example: 5×5 = 25 multiplies + adds per pixel.
* If your image has millions of pixels, this gets expensive.

---

## 🔹 Step 2: The idea of separability

Sometimes a 2D filter kernel can be split into two **1D filters**:

* First convolve **horizontally** (row by row).
* Then convolve **vertically** (column by column).

Now the cost per pixel is only:

$$
2K \quad \text{instead of} \quad K^2
$$

So for K=5, that’s 10 operations instead of 25 → more than 2× faster. For big kernels (like Gaussian blurs of size 15×15 or 31×31), this makes a **huge difference**.

---

## 🔹 Step 3: How do we know if a kernel is separable?

Mathematically, a kernel $K$ is separable if it can be written as an **outer product** of two vectors:

$$
K = v h^T
$$

* $v$ is a vertical 1D kernel (a column vector).
* $h^T$ is a horizontal 1D kernel (a row vector).
* Their outer product makes a 2D matrix.

Example:
Box blur 3×3 kernel

$$
K = \frac{1}{9}
\begin{bmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{bmatrix}
$$

This equals:

$$
K = \Big(\frac{1}{3}
\begin{bmatrix}
1 \\ 1 \\ 1
\end{bmatrix}\Big)
\Big(\frac{1}{3}
\begin{bmatrix}
1 & 1 & 1
\end{bmatrix}\Big)
$$

So the 2D box blur is separable: do a 1D blur across rows, then a 1D blur across columns.

---

## 🔹 Step 4: Gaussian blur (classic example)

A 2D Gaussian kernel is separable:

$$
G(x,y) = G(x) \cdot G(y)
$$

So instead of a giant 31×31 Gaussian (961 operations per pixel), you do a 31-tap horizontal filter + 31-tap vertical filter (62 operations per pixel). This is why **every real-time graphics system** uses separable Gaussian blurs.

---

## 🔹 Step 5: SVD test for separability

Not all kernels are separable. To check:

1. Treat the kernel $K$ as a matrix.
2. Do **Singular Value Decomposition (SVD)**:

   $$
   K = \sum_i \sigma_i u_i v_i^T
   $$
3. * If only **1 singular value** $\sigma_0$ is nonzero → kernel is perfectly separable.
   * If multiple singular values are nonzero → kernel is **not strictly separable**.

👉 But you can **approximate** a non-separable kernel using a sum of a few separable ones (keeping the biggest singular values). That’s like compressing the kernel.

---

## 🔹 Step 6: Why do we care?

* **Speed**: huge savings, especially for big blurs.
* **Memory/cache friendliness**: 1D passes are more cache-efficient.
* **Design**: Many useful filters (box blur, Gaussian, Sobel, bilinear interpolation) are separable.

---

## 🔹 Step 7: Examples from the book’s Fig 3.14

* (a) **Box filter (5×5)**: separable into \[1,1,1,1,1] horizontal × same vertical.
* (b) **Bilinear**: separable.
* (c) **Gaussian**: separable.
* (d) **Sobel**: actually separable into \[1,2,1] (vertical) × \[−1,0,1] (horizontal).
* (e) **Corner filter**: not perfectly separable, needs more terms.

---

✅ **In plain English:**
Separable filtering is a trick: if your 2D filter is really just the product of a vertical 1D filter and a horizontal 1D filter, you can replace a slow 2D convolution with two fast 1D convolutions. This saves a ton of work and is why Gaussian blurs, Sobel filters, and box blurs are so efficient in practice.

---

The section is introducing **different types of kernels**, what they do, and why we use them.

---

## 🔹 Step 1: Box filter (moving average)

* **Kernel**: all ones, normalized (e.g. 3×3 → each entry = 1/9).
* **Operation**: Replace each pixel with the average of its neighbors.
* **Effect**: Blurs the image → smooths out small variations and noise.
* **Trick for efficiency**: Instead of re-computing sums, slide a window: add the new pixel entering the window, subtract the old pixel leaving. Even faster with “summed area tables” (integral images).
* **Intuition**: “Cheap blur” but creates blocky artifacts for large kernels.

---

## 🔹 Step 2: Tent / Bilinear filter (Bartlett filter)

* **Kernel**: looks like a pyramid (center = larger weight, edges = smaller weights).
  Example 3×3:

  $$
  \frac{1}{16}
  \begin{bmatrix}
  1 & 2 & 1 \\
  2 & 4 & 2 \\
  1 & 2 & 1
  \end{bmatrix}
  $$
* **How it’s built**: outer product of \[1,2,1] with itself (separable).
* **Effect**: Smoother than box filter; weights nearer the center pixel matter more.
* **Intuition**: Averages, but respects pixel proximity → looks more natural than uniform blur.

---

## 🔹 Step 3: Gaussian filter

* **Kernel**: bell-shaped (discrete sample of a Gaussian curve).
* **How it’s built**: convolving the tent filter with itself, or directly sampling Gaussian function.
* **Effect**: Best for smooth blurring; preserves rotational symmetry, reduces aliasing, widely used in computer vision and graphics.
* **Trick**: Separable into horizontal and vertical 1D Gaussians → very efficient.
* **Intuition**: The "gold standard blur" → natural-looking, used everywhere (cameras, Photoshop, CNNs preprocessing).

---

## 🔹 Step 4: Sharpening (unsharp masking)

* **Observation**: Blurring removes high-frequency details.
* **Trick**: Subtract the blurred image from the original → you isolate the **edges** (high frequencies).
* **Unsharp mask formula**:

  $$
  g_\text{sharp} = f + \gamma (f - h_\text{blur} * f)
  $$

  * $f$: original
  * $h_\text{blur} * f$: blurred version
  * $\gamma$: gain factor controlling strength
* **Effect**: Edges get boosted → image looks sharper.
* **Intuition**: Think of it like highlighting differences between original and smoothed copy. This was originally done in darkrooms with film photography.

---

## 🔹 Step 5: Sobel operator (edge extractor)

* **Kernel(s)**:
  Horizontal edge detector:

  $$
  \begin{bmatrix}
  -1 & 0 & 1 \\
  -2 & 0 & 2 \\
  -1 & 0 & 1
  \end{bmatrix}
  $$

  Vertical edge detector = transpose.
* **How it’s built**: separable into \[1,2,1]^T (smoothing vertically) × \[-1,0,1] (central difference horizontally).
* **Effect**: Highlights vertical (or horizontal) edges in image.
* **Intuition**: First smooth a bit to reduce noise, then compute gradient → detects edges reliably.

---

## 🔹 Step 6: Corner detector

* **Kernel**:
  Looks like second derivatives in both directions, e.g.

  $$
  \begin{bmatrix}
  1 & -2 & 1 \\
  -2 & 4 & -2 \\
  1 & -2 & 1
  \end{bmatrix}
  $$
* **Effect**: Responds when both horizontal and vertical intensity changes happen together (like at a corner).
* **Problem**: It also responds to diagonal edges → not rotation-invariant.
* **Intuition**: Good for a quick-and-dirty “cornerness” measure, but better detectors exist (Harris corner, SIFT keypoints).

---

## 🔹 Step 7: Big picture

* Box, tent, Gaussian → **smoothing / low-pass** (they keep slow changes, remove rapid changes).
* Sobel, corner filters → **derivative operators / high-pass** (they keep rapid changes, i.e. edges and corners).
* Unsharp masking → **combination** of both (low-pass to extract details, then add back to original).

---

✅ **In plain words**:

* Box blur = cheap average.
* Tent / bilinear = weighted average, smoother.
* Gaussian = best blur, symmetric, separable.
* Unsharp masking = blur + subtract → sharpen.
* Sobel = edges.
* Corner kernel = rough corner detector (but imperfect).

---
