
# what problem are we solving?

we want a new image **g** made from an old image **f** by looking at small neighborhoods around every pixel and combining them with fixed weights (a tiny stencil). thatâ€™s â€œlinear filteringâ€.

# the cast of characters (symbols)

* **f(i, j)**: input image value at row **i**, column **j**
* **g(i, j)**: output image value at row **i**, column **j**
* **h(k, l)**: the **kernel / mask / filter** weights (a small matrix like 3Ã—3, 5Ã—5, â€¦)
* **N**: the neighborhood (the set of offsets **(k, l)** the kernel covers, e.g., k,l âˆˆ {âˆ’1,0,1} for a 3Ã—3)

think of **h** as a rubber stamp with numbers on it. we place its center over each pixel of **f**, multiply, sum, and write the result into **g** at the same location.

---

# step 1 â€” correlation (often called â€œfilteringâ€ in practice)

**idea:** slide **h** across **f** without flipping **h**.

**rule:**
g(i, j) = Î£â‚–,â‚— f(i + k, j + l) Â· h(k, l)â€ƒâ€ƒ(â€œcorrelationâ€)

**read it:** for output pixel (i, j),

1. align the kernel center on (i, j),
2. for each kernel cell (k, l), pick the input pixel **f(i+k, j+l)** under it,
3. multiply by the weight **h(k, l)**,
4. sum all products â†’ thatâ€™s **g(i, j)**.

**notation shortcut:** g = f âŠ— h (âŠ— for correlation)

> most image librariesâ€™ â€œfilter2Dâ€ operations are this correlation rule. deep-learning â€œconv2dâ€ layers also use correlation (no flip) but historically call it â€œconvolutionâ€.

---

# step 2 â€” convolution (the only difference is a flip)

**idea:** same sliding, but first rotate the kernel 180Â° (flip in both x and y).

**rule:**
g(i, j) = Î£â‚–,â‚— f(i âˆ’ k, j âˆ’ l) Â· h(k, l)â€ƒâ€ƒ(â€œconvolutionâ€)
equivalently, g = f \* h ( \* for convolution)

**why this definition? (impulse response intuition)**

* let Î´(i, j) be an image thatâ€™s 0 everywhere except a single 1 at the origin (an â€œimpulseâ€).
* **convolution** with Î´ reproduces **h** exactly: h \* Î´ = h (nice: the kernel shows up unflipped).
* **correlation** with Î´ gives the **reflected** h (because correlation doesnâ€™t flip the kernel, so the reflection happens in the math).

**practical takeaway / mnemonic:**

* **correlation**: slide & sum (no flip)
* **convolution**: **flip**, then slide & sum

in many image-processing tasks, the flip doesnâ€™t change the effect when **h** is symmetric (e.g., a Gaussian blur), so people use the words loosely.

---

# step 3 â€” a tiny concrete example

**image patch (3Ã—3 around the target pixel):**

```
f = [ [10, 20, 10],
      [20, 40, 20],
      [10, 20, 10] ]
```

**box-blur kernel h (3Ã—3, normalized):**

```
h = (1/9) * [ [1,1,1],
              [1,1,1],
              [1,1,1] ]
```

**correlation at center pixel:** multiply each pair and sum:
(10+20+10 + 20+40+20 + 10+20+10) \* (1/9) = 180/9 = 20 â†’ g(center)=20.
convolution gives the same here because **h** is symmetric.

---

# step 4 â€” what â€œlinearâ€ and â€œshift-invariantâ€ mean (LSI)

both correlation and convolution (with a **fixed** kernel) are **linear shift-invariant (LSI)**:

**linear:** filtering(fâ‚€ + fâ‚) = filtering(fâ‚€) + filtering(fâ‚)
**shift-invariant:** if you shift the input, the output shifts the same way; the operator behaves the same everywhere (same kernel for all pixels).

thatâ€™s exactly what equations (3.16) and (3.17) say.

---

# step 5 â€” spatially varying kernels (not shift-invariant)

sometimes the kernel itself changes with position, e.g., h(k, l; i, j). then

```
g(i, j) = Î£â‚–,â‚— f(i âˆ’ k, j âˆ’ l) Â· h(k, l; i, j)
```

this models effects like defocus blur that varies with depth across the image. itâ€™s no longer shift-invariant because the rule depends on (i, j).

---

# step 6 â€” the matrix view (why fig. 3.12 shows a banded matrix)

you can â€œunrollâ€ the image into a long vector **f** and write filtering as a sparse matrix **H**:

g = H f

in 1D, convolving with h = \[Â¼, Â½, Â¼] produces a **tridiagonal Toeplitz** matrix (the same three weights repeated along diagonals). in 2D, you get a big sparse **block-Toeplitz with Toeplitz blocks** (BTTB). this viewpoint is handy for proofs and for connecting to linear algebra and Fourier analysis.

---

# step 7 â€” why we care about convolution mathematically

* **commutative:** f \* h = h \* f
* **associative:** (f \* hâ‚) \* hâ‚‚ = f \* (hâ‚ \* hâ‚‚)
* **Fourier magic:** ğ“•{f \* h} = ğ“•{f} Â· ğ“•{h} (convolution in space = multiplication in frequency).
  this is why we can do fast filtering via FFTs for large kernels.

---

# step 8 â€” practical bits youâ€™ll hit in code

* **boundary handling:** when the kernel spills off the edge, choose a rule: zero-pad, reflect, clamp, wrap. this changes edge appearance.
* **normalization:** for blurs, make weights sum to 1 so brightness stays similar.
* **sharpening / edges:** kernels with positive center and negative neighbors (e.g., Laplacian, Sobel) enhance edges or detect them.
* **library conventions:**

  * OpenCVâ€™s `filter2D`, SciPyâ€™s `correlate2d`, PyTorch/TF â€œconvâ€ layers â†’ **correlation** by default (no flip).
  * If you truly need mathematical convolution, flip the kernel yourself (rotate 180Â°) before calling.

---

## TL;DR

* **Filtering** = sliding a small weight matrix over the image, multiply-accumulate â†’ new pixel.
* **Correlation** = slide & sum (no flip).
* **Convolution** = **flip** the kernel, then slide & sum.
* Both are **linear** and **shift-invariant** when the kernel is fixed.
* Convolution plays beautifully with the Fourier transform (space-domain convolution â†” frequency-domain multiplication).


---

## ğŸ”¹ Step 1: Cost of a normal 2D convolution

Suppose you have a **KÃ—K kernel** (say 5Ã—5).

* For each output pixel, you multiply-add **KÂ² numbers**.

  * Example: 5Ã—5 = 25 multiplies + adds per pixel.
* If your image has millions of pixels, this gets expensive.

---

## ğŸ”¹ Step 2: The idea of separability

Sometimes a 2D filter kernel can be split into two **1D filters**:

* First convolve **horizontally** (row by row).
* Then convolve **vertically** (column by column).

Now the cost per pixel is only:

$$
2K \quad \text{instead of} \quad K^2
$$

So for K=5, thatâ€™s 10 operations instead of 25 â†’ more than 2Ã— faster. For big kernels (like Gaussian blurs of size 15Ã—15 or 31Ã—31), this makes a **huge difference**.

---

## ğŸ”¹ Step 3: How do we know if a kernel is separable?

Mathematically, a kernel $K$ is separable if it can be written as an **outer product** of two vectors:

$$
K = v h^T
$$

* $v$ is a vertical 1D kernel (a column vector).
* $h^T$ is a horizontal 1D kernel (a row vector).
* Their outer product makes a 2D matrix.

Example:
Box blur 3Ã—3 kernel

$$
K = \frac{1}{9}
\begin{bmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{bmatrix}
$$

This equals:

$$
K = \Big(\frac{1}{3}
\begin{bmatrix}
1 \\ 1 \\ 1
\end{bmatrix}\Big)
\Big(\frac{1}{3}
\begin{bmatrix}
1 & 1 & 1
\end{bmatrix}\Big)
$$

So the 2D box blur is separable: do a 1D blur across rows, then a 1D blur across columns.

---

## ğŸ”¹ Step 4: Gaussian blur (classic example)

A 2D Gaussian kernel is separable:

$$
G(x,y) = G(x) \cdot G(y)
$$

So instead of a giant 31Ã—31 Gaussian (961 operations per pixel), you do a 31-tap horizontal filter + 31-tap vertical filter (62 operations per pixel). This is why **every real-time graphics system** uses separable Gaussian blurs.

---

## ğŸ”¹ Step 5: SVD test for separability

Not all kernels are separable. To check:

1. Treat the kernel $K$ as a matrix.
2. Do **Singular Value Decomposition (SVD)**:

   $$
   K = \sum_i \sigma_i u_i v_i^T
   $$
3. * If only **1 singular value** $\sigma_0$ is nonzero â†’ kernel is perfectly separable.
   * If multiple singular values are nonzero â†’ kernel is **not strictly separable**.

ğŸ‘‰ But you can **approximate** a non-separable kernel using a sum of a few separable ones (keeping the biggest singular values). Thatâ€™s like compressing the kernel.

---

## ğŸ”¹ Step 6: Why do we care?

* **Speed**: huge savings, especially for big blurs.
* **Memory/cache friendliness**: 1D passes are more cache-efficient.
* **Design**: Many useful filters (box blur, Gaussian, Sobel, bilinear interpolation) are separable.

---

## ğŸ”¹ Step 7: Examples from the bookâ€™s Fig 3.14

* (a) **Box filter (5Ã—5)**: separable into \[1,1,1,1,1] horizontal Ã— same vertical.
* (b) **Bilinear**: separable.
* (c) **Gaussian**: separable.
* (d) **Sobel**: actually separable into \[1,2,1] (vertical) Ã— \[âˆ’1,0,1] (horizontal).
* (e) **Corner filter**: not perfectly separable, needs more terms.

---

âœ… **In plain English:**
Separable filtering is a trick: if your 2D filter is really just the product of a vertical 1D filter and a horizontal 1D filter, you can replace a slow 2D convolution with two fast 1D convolutions. This saves a ton of work and is why Gaussian blurs, Sobel filters, and box blurs are so efficient in practice.

---

The section is introducing **different types of kernels**, what they do, and why we use them.

---

## ğŸ”¹ Step 1: Box filter (moving average)

* **Kernel**: all ones, normalized (e.g. 3Ã—3 â†’ each entry = 1/9).
* **Operation**: Replace each pixel with the average of its neighbors.
* **Effect**: Blurs the image â†’ smooths out small variations and noise.
* **Trick for efficiency**: Instead of re-computing sums, slide a window: add the new pixel entering the window, subtract the old pixel leaving. Even faster with â€œsummed area tablesâ€ (integral images).
* **Intuition**: â€œCheap blurâ€ but creates blocky artifacts for large kernels.

---

## ğŸ”¹ Step 2: Tent / Bilinear filter (Bartlett filter)

* **Kernel**: looks like a pyramid (center = larger weight, edges = smaller weights).
  Example 3Ã—3:

  $$
  \frac{1}{16}
  \begin{bmatrix}
  1 & 2 & 1 \\
  2 & 4 & 2 \\
  1 & 2 & 1
  \end{bmatrix}
  $$
* **How itâ€™s built**: outer product of \[1,2,1] with itself (separable).
* **Effect**: Smoother than box filter; weights nearer the center pixel matter more.
* **Intuition**: Averages, but respects pixel proximity â†’ looks more natural than uniform blur.

---

## ğŸ”¹ Step 3: Gaussian filter

* **Kernel**: bell-shaped (discrete sample of a Gaussian curve).
* **How itâ€™s built**: convolving the tent filter with itself, or directly sampling Gaussian function.
* **Effect**: Best for smooth blurring; preserves rotational symmetry, reduces aliasing, widely used in computer vision and graphics.
* **Trick**: Separable into horizontal and vertical 1D Gaussians â†’ very efficient.
* **Intuition**: The "gold standard blur" â†’ natural-looking, used everywhere (cameras, Photoshop, CNNs preprocessing).

---

## ğŸ”¹ Step 4: Sharpening (unsharp masking)

* **Observation**: Blurring removes high-frequency details.
* **Trick**: Subtract the blurred image from the original â†’ you isolate the **edges** (high frequencies).
* **Unsharp mask formula**:

  $$
  g_\text{sharp} = f + \gamma (f - h_\text{blur} * f)
  $$

  * $f$: original
  * $h_\text{blur} * f$: blurred version
  * $\gamma$: gain factor controlling strength
* **Effect**: Edges get boosted â†’ image looks sharper.
* **Intuition**: Think of it like highlighting differences between original and smoothed copy. This was originally done in darkrooms with film photography.

---

## ğŸ”¹ Step 5: Sobel operator (edge extractor)

* **Kernel(s)**:
  Horizontal edge detector:

  $$
  \begin{bmatrix}
  -1 & 0 & 1 \\
  -2 & 0 & 2 \\
  -1 & 0 & 1
  \end{bmatrix}
  $$

  Vertical edge detector = transpose.
* **How itâ€™s built**: separable into \[1,2,1]^T (smoothing vertically) Ã— \[-1,0,1] (central difference horizontally).
* **Effect**: Highlights vertical (or horizontal) edges in image.
* **Intuition**: First smooth a bit to reduce noise, then compute gradient â†’ detects edges reliably.

---

## ğŸ”¹ Step 6: Corner detector

* **Kernel**:
  Looks like second derivatives in both directions, e.g.

  $$
  \begin{bmatrix}
  1 & -2 & 1 \\
  -2 & 4 & -2 \\
  1 & -2 & 1
  \end{bmatrix}
  $$
* **Effect**: Responds when both horizontal and vertical intensity changes happen together (like at a corner).
* **Problem**: It also responds to diagonal edges â†’ not rotation-invariant.
* **Intuition**: Good for a quick-and-dirty â€œcornernessâ€ measure, but better detectors exist (Harris corner, SIFT keypoints).

---

## ğŸ”¹ Step 7: Big picture

* Box, tent, Gaussian â†’ **smoothing / low-pass** (they keep slow changes, remove rapid changes).
* Sobel, corner filters â†’ **derivative operators / high-pass** (they keep rapid changes, i.e. edges and corners).
* Unsharp masking â†’ **combination** of both (low-pass to extract details, then add back to original).

---

âœ… **In plain words**:

* Box blur = cheap average.
* Tent / bilinear = weighted average, smoother.
* Gaussian = best blur, symmetric, separable.
* Unsharp masking = blur + subtract â†’ sharpen.
* Sobel = edges.
* Corner kernel = rough corner detector (but imperfect).

---
