
talked about interrupts, signals

talking about the overhead of system calls.

when the system traps into kernel mode there is overhead caused because a lot operation have to be done to switch into kernel mode. including things like setting the mode register and other things.

jump to kernel -> execute system call -> return back.

when some error or something happens when a kernel instruction is executing, it generates a signal and to handle this every application has to provide signal handlers that are maintained in a signal handler table that has the signals that the OS supports and the handler addresses.

**Microkernels**

to avoid all the overhead discussed above we built microkernels that have very less functionalities implemented in kernel level and all other things implemented in the user level.

question : why does it become more efficient if the same amount of overhead is tranferred to user level, is it because in user mode there can be process switches and all to make the cpu utilization high and in kernel mode the instruciton has to execute completely before a different process can be brought in.

answer : prof said this will reduce the amount of context switches needed and the amount of IPC that needs to be done. elaborate.....

question : have to read about hipervisors, hipervised systems and their usecases.



# ‚öôÔ∏è Advanced Operating Systems ‚Äì Notes

---

## üîπ 1. Interrupts vs. Signals

### Interrupts

* **Definition**: Hardware-triggered events (asynchronous to program execution).
* Caused by devices (e.g., disk I/O completion, keyboard input, timer).
* CPU stops current instruction, saves context, and jumps to an **Interrupt Service Routine (ISR)**.
* Handled at **kernel level**.

### Signals

* **Definition**: Software-triggered notifications sent to processes.
* Used to handle exceptional conditions (e.g., divide-by-zero, segmentation fault, kill command).
* OS maintains a **signal handler table**:

  * Keys = signal numbers.
  * Values = handler function addresses provided by applications.
* Default handlers: If the process doesn‚Äôt provide one, the OS uses its default (e.g., terminate on `SIGSEGV`).

üî∏ **Difference**:

* Interrupt = hardware ‚Üí kernel.
* Signal = kernel ‚Üí process (software-level notification).

---

## üîπ 2. Overhead of System Calls

### System Call Path

1. Process executes an instruction like `read()`.
2. CPU **traps** into **kernel mode** (mode switch).
3. Kernel executes system call handler.
4. Kernel returns control to user mode.

### Why overhead?

* Switching from **user ‚Üí kernel ‚Üí user** is expensive:

  * Save user context.
  * Change **mode register** (privilege level).
  * Switch to kernel stack.
  * Flush TLB/modify page tables (sometimes).
  * Jump to kernel system call handler.
* This back-and-forth is costly when done frequently.

---

## üîπ 3. Microkernels

### Idea

* Instead of placing everything in kernel (as in **monolithic kernels** like Linux), keep kernel minimal:

  * Only core services (memory mgmt, CPU scheduling, IPC).
  * Everything else (file systems, drivers, networking) ‚Üí **user space servers**.

### Benefit

* Reduces kernel complexity ‚Üí easier to maintain, smaller trusted code base.
* **Efficiency reasoning**:

  * In monolithic design, every request to file system, drivers, etc., requires **system calls + kernel mode transitions**.
  * In microkernels, services run in user mode ‚Üí fewer traps into kernel.
  * The professor said:

    * **Fewer context switches & IPC calls**.
    * Once in user mode, communication between services (via IPC) can be optimized.
    * Kernel does only lightweight mediation instead of executing full functionality.

### Example OS:

* **Minix**, **QNX**, **seL4** ‚Üí microkernel-based.
* **Linux, Windows** ‚Üí monolithic kernels (though they have modular elements).

---

## üîπ 4. Key Question

**Q:** Why does moving services to user mode help? Isn‚Äôt the overhead just moved from kernel ‚Üí user?

**A (prof‚Äôs point):**

* In kernel mode ‚Üí execution must finish before switching to another process.
* In user mode ‚Üí scheduler has more flexibility to preempt, overlap, and optimize CPU utilization.
* Also, microkernels reduce the number of **heavy context switches** by using **lighter-weight IPC mechanisms** instead of repeated syscalls.

---

## üîπ 5. Hypervisors (To Read)

### What is a Hypervisor?

* Software/firmware layer that enables **virtualization** by allowing multiple OS instances (guests) to share the same physical hardware.

### Types

1. **Type 1 (Bare Metal Hypervisors)**

   * Runs directly on hardware.
   * Examples: **VMware ESXi, Microsoft Hyper-V, Xen**.
   * Used in data centers ‚Üí high performance, direct access to hardware.

2. **Type 2 (Hosted Hypervisors)**

   * Runs on top of a host OS.
   * Examples: **VMware Workstation, VirtualBox**.
   * Easier for development/testing, less efficient than Type 1.

### Use Cases

* Server virtualization (consolidating multiple servers).
* Cloud computing (AWS, Azure, GCP use hypervisors).
* Security (isolating workloads in separate VMs).
* Running multiple OSes for testing.

---

# ‚úÖ Summary

* **Interrupts** = hardware ‚Üí kernel, **Signals** = kernel ‚Üí user process.
* **System calls** involve expensive user-kernel switches.
* **Microkernels** reduce this overhead by keeping only essentials in kernel and pushing everything else to user mode servers.
* This reduces **context switching and IPC overhead**.
* **Hypervisors** are the backbone of virtualization, allowing multiple OSes to run on the same hardware.
