
Improving file-system performance is essential due to **extreme speed differences** between:
- Memory (10 ns)
- SSDs (tens of Âµs)
- Hard disks (seek + rotation delays â†’ ~10 ms)

### âš¡ Optimization Techniques Covered:
1. **Caching**
2. **Block Read-Ahead**
3. **Disk-Arm Motion Reduction**

---

### ğŸ§  Caching (Block/Buffer Cache)

- A **cache** is a memory-resident set of disk blocks to minimize disk I/O.
- On a **read**:
  - Check if block is in cache (via hash table)
  - If yes â†’ return directly
  - If no â†’ read from disk and insert into cache
- **Replacement**: Use standard page-replacement strategies (LRU, FIFO, etc.)

#### ğŸ§­ Modified LRU Strategy:
To ensure both performance *and* crash-resilience:
- Assess two factors per block:
  1. Will it be used again soon?
  2. Is it critical for **file-system consistency**?

| Block Type                | Usage Strategy                          | Write Strategy              |
|--------------------------|------------------------------------------|-----------------------------|
| I-node / indirect blocks | Rarely reused soon â†’ front of LRU list  | **Write immediately if dirty** |
| Data blocks (full/partial)| Likely reused â†’ rear of LRU list       | May be deferred             |

#### ğŸ” Write-Through vs Delayed Write:
- **UNIX**: Periodic `sync()` every 30s (via background `update` process)
- **Windows (legacy)**: Write-through cache â€“ immediate disk write after every modification

| Strategy        | Pros                      | Cons                        |
|----------------|---------------------------|-----------------------------|
| Delayed write  | Efficient                 | Risk of data loss on crash  |
| Write-through  | Safe for removable disks  | Higher I/O overhead         |

#### ğŸ§© Page Cache vs Buffer Cache:
- **Page Cache**: Caches file *pages* â†’ works with memory-mapped files.
- **Buffer Cache**: Caches *disk blocks*.
- **Unified cache** preferred â†’ reduces redundancy and simplifies cache coherence.

---

### â© Block Read-Ahead

- Boosts performance by **pre-loading block `k+1`** after `k` is read.
- **Adaptive**:
  - Enable read-ahead if access pattern appears **sequential**.
  - Disable on **random access** (e.g., after seek).
- Adds **minimal risk** if prediction is wrong.

---

### ğŸ§² Reducing Disk-Arm Motion

#### 1. ğŸ§± **Block Clustering**
- Group **sequential blocks** together to reduce seek operations.
- Allocate groups of blocks near each other, ideally in same **cylinder**.

#### 2. ğŸ“ **Cylinder Groups**
- Instead of placing all i-nodes at disk start:
  - **Group i-nodes with their data blocks** within cylinder groups.
  - Each group includes:
    - I-nodes
    - Data blocks
    - Free space bitmap

![[{02149781-494C-4862-9A10-E63F935C9E9A}.png]]
- New files attempt to place i-node and data in **same group**, else nearby.

#### ğŸ”„ Applies to:
- **HDDs only**: with mechanical seek and rotation delays.
- **SSDs**: unaffected by seek time â†’ **random access â‰ˆ sequential access**.

---
## ğŸ§© 4.4.5 Defragmenting Disks

### ğŸŒ€ The Problem:
- Over time, files get created, deleted, and modified â†’ leading to **fragmentation**.
- Fragmentation scatters file blocks â†’ degrading **disk performance**.

### ğŸ§¹ The Solution: **Defragmentation**
- Moves files to **contiguous regions** and consolidates free space.
- Improves **sequential access performance**.

### ğŸ› ï¸ Defragmentation Tools:
- **Windows**: Built-in `defrag` tool (should be run periodically on HDDs).
- **Works best** when there's large **contiguous free space** at the end of partition.
- **Some files cannot be moved** (e.g., paging file, hibernation file, journaling logs).

> **Note:** To resize a partition when such immovable files are near the end â†’ delete them, resize, then recreate.

### ğŸ§ Linux and SSDs:
- **Linux (ext3/ext4)**: Fragmentation-resistant design â†’ defragmentation rarely needed.
- **SSDs**: No seek time = no performance loss from fragmentation.
  - Defragmentation is **counterproductive**:
    - No performance benefit.
    - **Reduces SSD lifespan** due to unnecessary write/erase cycles.

---

## ğŸ“¦ 4.4.6 Compression and Deduplication

### ğŸ” Compression in File Systems
- Saves storage by encoding **repetitive patterns** efficiently.
- Used by:
  - **NTFS** (Windows)
  - **Btrfs**, **ZFS** (Linux and cross-platform)
- Works on:
  - Specific folders or entire filesystem.
- Technique: Detects matching byte patterns, replaces duplicates with references.

### â™»ï¸ Deduplication

#### ğŸ§  What is it?
- Eliminates **duplicate data** across:
  - Files
  - File chunks
  - Disk blocks

#### ğŸ“Œ Use cases:
- Cloud systems, shared workstations, backups (where data is often duplicated)

#### ğŸ§± Granularities:
- Entire files
- File chunks (e.g., 128 KB)
- Individual disk blocks

#### ğŸ§¬ Write-time Strategies:
| Type               | Description                                                                 |
|--------------------|-----------------------------------------------------------------------------|
| **Inline**         | Dedup during writes; computes hash of each chunk â†’ compare â†’ reference if match |
| **Post-process**   | Write first, dedup later in background â†’ **faster writes**, **slower dedup**   |

> âš ï¸ Inline dedup slows write operations due to on-the-fly hashing.

#### ğŸ” Verification & Hash Collisions
- Dedup uses **hashes** to detect duplicates.
- **Hash collisions**, though rare, can cause **data loss**.
  - Some systems accept this risk.
  - Safer systems **verify actual data content** before deduplication.

---
## ğŸ” 4.4.7 Secure File Deletion and Disk Encryption

### ğŸ—‘ï¸ Why "Deleting" a File Isnâ€™t Enough
- OS-level file deletion only:
  - Removes the file from directory listings
  - Frees up the i-node and blocks for reuse
- Actual content **remains** on disk and is **recoverable** by:
  - Booting from another OS
  - Reading raw disk blocks directly

### ğŸ’£ Physical Destruction
- The **only guaranteed method** of secure deletion:
  > Burn the disk using **thermite** at ~2500Â°C  
  - Effective, but... not reusable ğŸ˜…

---

### ğŸ§¹ Software-Based Secure Deletion
- Even **overwriting** data with zeros may be insufficient:
  - Magnetic residue on **adjacent tracks** can be analyzed
  - Data may exist in **hidden cache**, **backups**, or **unmapped flash blocks** (on SSDs)
- ğŸ” Recommended approach:
  - Overwrite data **3â€“7 times** with a combination of **zeros** and **random values**
  - Tools like `shred`, `DBAN`, or other secure erasers automate this

---

### ğŸ§Š Problems with SSDs
- SSDs use a **Flash Translation Layer (FTL)**:
  - Prevents full control over physical writes
  - Old data may **persist** even after logical deletion
- ğŸ” Hence, overwriting doesn't guarantee erasure

---

### ğŸ” Full Disk Encryption (FDE)

#### ğŸ’¡ Key Concept:
Encrypt **everything** on disk so that even raw bit-level access is useless without a key.

#### ğŸ” Implementation Options:
- **Software-based FDE**: Done by OS using algorithms like **AES**
- **Hardware-based FDE**: Self-Encrypting Drives (SEDs) with onboard crypto logic

#### ğŸš¨ Caveats:
- SEDs have shown **security flaws** in specification and implementation (Meijer & Van Gastel, 2019)
- Relying solely on hardware is risky unless vetted

---

### ğŸªª Windows Example: BitLocker

- Uses **AES encryption**
- Encrypts with a **Volume Master Key (VMK)**
- VMK is encrypted and can be unlocked via:
  - **User password**
  - **Recovery key** (auto-generated)
  - **TPM (Trusted Platform Module)**: Hardware-based secure key store

> âœ… Fully transparent to users. Most are unaware encryption is even active.

---

### ğŸ” Key Takeaways:
- File deletion â‰  data removal
- SSDs complicate secure erasure due to FTL
- Full disk encryption is **essential** for protecting at-rest data
- Even with encryption, **key management** and **device trust** are critical

---

