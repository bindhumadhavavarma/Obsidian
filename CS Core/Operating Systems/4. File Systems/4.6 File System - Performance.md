
Improving file-system performance is essential due to **extreme speed differences** between:
- Memory (10 ns)
- SSDs (tens of µs)
- Hard disks (seek + rotation delays → ~10 ms)

### ⚡ Optimization Techniques Covered:
1. **Caching**
2. **Block Read-Ahead**
3. **Disk-Arm Motion Reduction**

---

### 🧠 Caching (Block/Buffer Cache)

- A **cache** is a memory-resident set of disk blocks to minimize disk I/O.
- On a **read**:
  - Check if block is in cache (via hash table)
  - If yes → return directly
  - If no → read from disk and insert into cache
- **Replacement**: Use standard page-replacement strategies (LRU, FIFO, etc.)

#### 🧭 Modified LRU Strategy:
To ensure both performance *and* crash-resilience:
- Assess two factors per block:
  1. Will it be used again soon?
  2. Is it critical for **file-system consistency**?

| Block Type                | Usage Strategy                          | Write Strategy              |
|--------------------------|------------------------------------------|-----------------------------|
| I-node / indirect blocks | Rarely reused soon → front of LRU list  | **Write immediately if dirty** |
| Data blocks (full/partial)| Likely reused → rear of LRU list       | May be deferred             |

#### 🔁 Write-Through vs Delayed Write:
- **UNIX**: Periodic `sync()` every 30s (via background `update` process)
- **Windows (legacy)**: Write-through cache – immediate disk write after every modification

| Strategy        | Pros                      | Cons                        |
|----------------|---------------------------|-----------------------------|
| Delayed write  | Efficient                 | Risk of data loss on crash  |
| Write-through  | Safe for removable disks  | Higher I/O overhead         |

#### 🧩 Page Cache vs Buffer Cache:
- **Page Cache**: Caches file *pages* → works with memory-mapped files.
- **Buffer Cache**: Caches *disk blocks*.
- **Unified cache** preferred → reduces redundancy and simplifies cache coherence.

---

### ⏩ Block Read-Ahead

- Boosts performance by **pre-loading block `k+1`** after `k` is read.
- **Adaptive**:
  - Enable read-ahead if access pattern appears **sequential**.
  - Disable on **random access** (e.g., after seek).
- Adds **minimal risk** if prediction is wrong.

---

### 🧲 Reducing Disk-Arm Motion

#### 1. 🧱 **Block Clustering**
- Group **sequential blocks** together to reduce seek operations.
- Allocate groups of blocks near each other, ideally in same **cylinder**.

#### 2. 📍 **Cylinder Groups**
- Instead of placing all i-nodes at disk start:
  - **Group i-nodes with their data blocks** within cylinder groups.
  - Each group includes:
    - I-nodes
    - Data blocks
    - Free space bitmap

![[{02149781-494C-4862-9A10-E63F935C9E9A}.png]]
- New files attempt to place i-node and data in **same group**, else nearby.

#### 🔄 Applies to:
- **HDDs only**: with mechanical seek and rotation delays.
- **SSDs**: unaffected by seek time → **random access ≈ sequential access**.

---
## 🧩 4.4.5 Defragmenting Disks

### 🌀 The Problem:
- Over time, files get created, deleted, and modified → leading to **fragmentation**.
- Fragmentation scatters file blocks → degrading **disk performance**.

### 🧹 The Solution: **Defragmentation**
- Moves files to **contiguous regions** and consolidates free space.
- Improves **sequential access performance**.

### 🛠️ Defragmentation Tools:
- **Windows**: Built-in `defrag` tool (should be run periodically on HDDs).
- **Works best** when there's large **contiguous free space** at the end of partition.
- **Some files cannot be moved** (e.g., paging file, hibernation file, journaling logs).

> **Note:** To resize a partition when such immovable files are near the end → delete them, resize, then recreate.

### 🐧 Linux and SSDs:
- **Linux (ext3/ext4)**: Fragmentation-resistant design → defragmentation rarely needed.
- **SSDs**: No seek time = no performance loss from fragmentation.
  - Defragmentation is **counterproductive**:
    - No performance benefit.
    - **Reduces SSD lifespan** due to unnecessary write/erase cycles.

---

## 📦 4.4.6 Compression and Deduplication

### 🔐 Compression in File Systems
- Saves storage by encoding **repetitive patterns** efficiently.
- Used by:
  - **NTFS** (Windows)
  - **Btrfs**, **ZFS** (Linux and cross-platform)
- Works on:
  - Specific folders or entire filesystem.
- Technique: Detects matching byte patterns, replaces duplicates with references.

### ♻️ Deduplication

#### 🧠 What is it?
- Eliminates **duplicate data** across:
  - Files
  - File chunks
  - Disk blocks

#### 📌 Use cases:
- Cloud systems, shared workstations, backups (where data is often duplicated)

#### 🧱 Granularities:
- Entire files
- File chunks (e.g., 128 KB)
- Individual disk blocks

#### 🧬 Write-time Strategies:
| Type               | Description                                                                 |
|--------------------|-----------------------------------------------------------------------------|
| **Inline**         | Dedup during writes; computes hash of each chunk → compare → reference if match |
| **Post-process**   | Write first, dedup later in background → **faster writes**, **slower dedup**   |

> ⚠️ Inline dedup slows write operations due to on-the-fly hashing.

#### 🔍 Verification & Hash Collisions
- Dedup uses **hashes** to detect duplicates.
- **Hash collisions**, though rare, can cause **data loss**.
  - Some systems accept this risk.
  - Safer systems **verify actual data content** before deduplication.

---
## 🔐 4.4.7 Secure File Deletion and Disk Encryption

### 🗑️ Why "Deleting" a File Isn’t Enough
- OS-level file deletion only:
  - Removes the file from directory listings
  - Frees up the i-node and blocks for reuse
- Actual content **remains** on disk and is **recoverable** by:
  - Booting from another OS
  - Reading raw disk blocks directly

### 💣 Physical Destruction
- The **only guaranteed method** of secure deletion:
  > Burn the disk using **thermite** at ~2500°C  
  - Effective, but... not reusable 😅

---

### 🧹 Software-Based Secure Deletion
- Even **overwriting** data with zeros may be insufficient:
  - Magnetic residue on **adjacent tracks** can be analyzed
  - Data may exist in **hidden cache**, **backups**, or **unmapped flash blocks** (on SSDs)
- 🔁 Recommended approach:
  - Overwrite data **3–7 times** with a combination of **zeros** and **random values**
  - Tools like `shred`, `DBAN`, or other secure erasers automate this

---

### 🧊 Problems with SSDs
- SSDs use a **Flash Translation Layer (FTL)**:
  - Prevents full control over physical writes
  - Old data may **persist** even after logical deletion
- 🔐 Hence, overwriting doesn't guarantee erasure

---

### 🔐 Full Disk Encryption (FDE)

#### 💡 Key Concept:
Encrypt **everything** on disk so that even raw bit-level access is useless without a key.

#### 🔐 Implementation Options:
- **Software-based FDE**: Done by OS using algorithms like **AES**
- **Hardware-based FDE**: Self-Encrypting Drives (SEDs) with onboard crypto logic

#### 🚨 Caveats:
- SEDs have shown **security flaws** in specification and implementation (Meijer & Van Gastel, 2019)
- Relying solely on hardware is risky unless vetted

---

### 🪪 Windows Example: BitLocker

- Uses **AES encryption**
- Encrypts with a **Volume Master Key (VMK)**
- VMK is encrypted and can be unlocked via:
  - **User password**
  - **Recovery key** (auto-generated)
  - **TPM (Trusted Platform Module)**: Hardware-based secure key store

> ✅ Fully transparent to users. Most are unaware encryption is even active.

---

### 🔐 Key Takeaways:
- File deletion ≠ data removal
- SSDs complicate secure erasure due to FTL
- Full disk encryption is **essential** for protecting at-rest data
- Even with encryption, **key management** and **device trust** are critical

---

