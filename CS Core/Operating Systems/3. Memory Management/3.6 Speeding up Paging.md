---

### 🧠 Section 3.3.3 – Speeding Up Paging

---

Virtual memory enables powerful abstractions, but it introduces new performance challenges. Two core problems must be addressed in paging systems:

---

### 🔸 The Two Major Problems

1. **Fast Mapping Requirement**  
   - Every memory access (even fetching instructions) requires virtual-to-physical address translation.
   - If instruction execution takes ~1 nanosecond, page table lookup must be done in **<0.2 ns** to avoid becoming a bottleneck.
   - Multiple memory accesses per instruction can significantly slow down execution.

2. **Huge Page Table Size**  
   - With 48-bit virtual addresses and 4-KB pages, we get **64 billion virtual pages**.
   - A single page table per process would require **hundreds of GBs** just to store, which is **impractical**.

---

### 🔹 Basic Approaches and Their Limitations

#### 🧱 Hardware-Based Page Table (Registers)

- Store entire page table in fast registers.
- Advantage: no memory reference needed for translation.
- Disadvantage: works only for very small tables; infeasible for large address spaces.

#### 💾 Page Table in Main Memory

- Store page table in RAM.
- MMU has a single register pointing to page table.
- Simple and memory-efficient.
- **Disadvantage**: incurs one or more memory reads **per memory access**, significantly reducing performance.

---

### 🔸 Solution: Translation Lookaside Buffer (TLB)

#### 🧠 Core Idea:

Programs access only a **small working set** of pages frequently.

> So instead of looking up the page table for every access, cache recent translations in a **special hardware structure** called a **TLB**.

---

### 🔹 Translation Lookaside Buffer (TLB)

- A **small, associative cache** inside the MMU.
- Stores recent **(Virtual Page Number → Page Frame Number)** mappings.
- Typically 8 to 256 entries.
- Each TLB entry contains:
  - Virtual Page Number
  - Page Frame Number
  - Protection bits (e.g., R/W/X)
  - Modified (Dirty) bit
  - Valid bit

#### 🧪 Example (Fig. 3-12):

- Virtual pages 19–21 → code
- Pages 129–130 → data
- Page 140 → index variables
- Pages 860–861 → stack

---

### 🔸 TLB Operation

1. Virtual address sent to MMU.
2. MMU **checks TLB first** (parallel comparison).
3. If **hit**:
   - Returns frame immediately.
   - Ensures access is valid (e.g., no write to R/O).
4. If **miss**:
   - MMU performs regular page table lookup.
   - Replaces a TLB entry (eviction).
   - Updates page table and TLB accordingly.

> 🧠 Modified (dirty) bit is copied back to the page table when TLB entry is evicted.

---

### 🔹 OS and TLB Synchronization

- If OS changes access rights (e.g., makes a page writable):
  - It must **flush the old entry** from the TLB.
  - Otherwise, stale permissions will persist.

---

### 🔸 Software-Managed TLBs

Not all MMUs handle TLB misses in hardware.

#### ⚙️ Software TLB Handling:

- Used by architectures like **SPARC**, **MIPS**, **PA-RISC**.
- On a TLB miss:
  1. MMU raises a **TLB fault**.
  2. OS must:
     - Walk the page table.
     - Replace a TLB entry.
     - Resume the faulted instruction.

#### 📉 TLB Miss Frequency

- TLBs are small → **misses happen often**.
- Page faults are rare (since many pages are in memory).
- **TLB misses ≫ Page faults**

---

### 🔸 Soft vs Hard Misses

| Type | Cause | Time to Handle | Description |
|------|-------|----------------|-------------|
| **Soft Miss** | Page is in memory, but not in TLB | Nanoseconds | TLB update only |
| **Hard Miss (Page Fault)** | Page not in memory | Milliseconds | Page must be loaded from disk |
| **Minor Page Fault** | Page is in memory (used by another process) | Microseconds | Only mapping is missing |
| **Major Page Fault** | Page not in memory | Milliseconds | Load from disk/SSD |
| **Invalid Access** | Illegal address | Immediate termination | Triggers segmentation fault |

---

### 🧠 Summary of Performance Trade-offs

- TLBs help **cache the working set** of pages.
- A **64-entry TLB** is often enough to dramatically reduce misses.
- But increasing TLB size uses chip area better spent on caches.
- TLB misses are common, but **software-handled TLBs** are acceptable if managed efficiently.

---

### ✅ Key Takeaways

- **TLB = essential optimization** to make paging feasible.
- Misses:
  - Soft → cheap
  - Hard → expensive
- TLBs accelerate paging, but **can’t solve everything**—very large address spaces still need smarter page table structures.

---

In the next section, we'll explore how to handle **huge page tables** with **multilevel and inverted page table designs**.

---
TLBs have something called tagging that tell which process a particular entry belongs to, this allows to switch processes without having to flush the entire tlb.