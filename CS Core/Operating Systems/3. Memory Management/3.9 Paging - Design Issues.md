
## 🧩 3.5 Design Issues for Paging Systems

---

> Understanding paging mechanics isn't enough—like chess, **mastery requires strategy**. OS designers must consider key policies and trade-offs to ensure performance.

---

## 🔀 3.5.1 Local vs Global Allocation Policies

---

### 🧠 The Core Question

When a page fault occurs, **whose pages should we evict?**

---

### 🗂️ Two Strategies

| Policy | Description | Example |
|--------|-------------|---------|
| **Local Replacement** | Replace a page **owned by the faulting process** only | Fig. 3-22(b): A6 replaces A5 |
| **Global Replacement** | Replace **any page** in memory, regardless of owner | Fig. 3-22(c): A6 replaces B3 |

---

### 📊 Trade-offs

- **Global**: Adapts to changing working set sizes; **better overall performance**.
- **Local**: Fixed allocation per process → can lead to **thrashing** or **waste**.

> Global works well when processes have **variable memory demands**, but it requires active **monitoring and reallocation**.

---

### 🧮 Allocation Techniques

- **Equal Shares**: Divide available frames equally among processes.
- **Proportional Allocation**: Allocate based on process size.
- **Minimum Guarantee**: Ensure small processes can still run (e.g., instruction operands might span 6 pages).

---

### 📈 PFF – Page Fault Frequency Algorithm

- **Goal**: Keep page fault rate within acceptable bounds.

#### 🔄 Adjustment Logic:
- **Too many faults** (Line A, Fig. 3-23) → **Increase** page frames.
- **Too few faults** (Line B) → **Decrease** page frames.

> PFF **does not choose which page to evict**, just adjusts the **size of allocations**.

---

## 🚦 3.5.2 Load Control

---

### 💥 Thrashing Despite Smart Allocation?

Even the best algorithms can't save the system if **total working sets > memory**.

---

### 🧹 Solutions

1. **💀 OOM Killer (Out of Memory)**
   - Terminates processes with **high memory usage** or **low priority**.
   - Minimizes overall kills while freeing space.

2. **💾 Swapping Out**
   - Move full processes to disk temporarily.
   - Redistribute their frames to **active processes**.

3. **📊 Two-Level Scheduling**
   - Some processes reside on disk, some run.
   - Scheduler juggles **who's in memory** to optimize throughput.

---

### 📉 When Multiprogramming is Too Low

- Too few processes → **CPU underutilized**.
- Must balance **paging load vs CPU usage**.

---

### ✂️ Memory Reduction Techniques

- **🧬 Deduplication (Same Page Merging)**:
  - Detect identical pages across processes.
  - Map both to a **single shared frame** (copy-on-write if modified).
  - Saves memory with **no performance loss**.

---

## 🧼 3.5.3 Cleaning Policy

---

### 🧽 The Problem

- All frames are **dirty and full**.
- Every page fault requires a **write before load**.

---

### 🔄 Paging Daemon

A **background process** that:
- Sleeps most of the time.
- Wakes up to ensure **free, clean pages** are available.
- Writes dirty pages to disk **before** they’re needed.

---

### 🕰️ Two-Handed Clock

| Hand | Role |
|------|------|
| **Front Hand** | Controlled by paging daemon. Cleans dirty pages preemptively. |
| **Back Hand** | Handles actual page replacement on faults. |

> Ensures the **back hand hits clean pages**, improving performance.

Here’s the styled, structured, Obsidian-friendly summary for **Section 3.5.4 – Page Size**:

## 📏 3.5.4 Page Size

---

### 🧠 OS Control Over Page Size

Even if the **hardware** uses, say, 4 KB pages, the **OS** can group them logically (e.g., pair two 4 KB pages to act as an 8 KB page). This offers flexibility but brings trade-offs.

---

## ⚖️ Trade-offs in Page Size

---

### 🔻 Arguments for **Small Pages**

#### 1. 🧱 Reduced Internal Fragmentation
- Processes rarely use a perfect multiple of the page size.
- **Half of the last page** is wasted on average →  
  Waste per process = `p/2`  
  Total for `n` segments = `n × p/2`

#### 2. 🧠 Finer-Grained Memory Use
- Programs with **phased execution** benefit:
  - 4 KB phase → needs only 4 KB if page = 4 KB
  - 32 KB page → always needs full 32 KB in memory

> Small pages = less memory **waste per phase**

---

### 🔺 Arguments for **Large Pages**

#### 1. 🧾 Smaller Page Tables
- A 32 KB program needs:
  - 4 pages if page size = 8 KB
  - 64 pages if page size = 512 B

#### 2. 🚀 Disk I/O Efficiency
- Disk seeks dominate transfer time.
- 64 × 512 B pages → 640 ms  
- 4 × 8 KB pages → 48 ms  
> Large pages = **faster bulk transfers**

#### 3. 🧠 TLB Efficiency
- TLBs hold a **limited number** of entries.
- Fewer entries needed if each page is larger.
  - 1 MB memory, 4 KB pages → 16 TLB entries
  - 2 MB pages → 1 TLB entry
> Large pages reduce **TLB pressure**

---

### 🧪 Mixed Page Sizes in Practice

- **Kernel**: large pages  
- **User processes**: small pages  
- **Transparent Huge Pages**: OS finds/creates **contiguous memory regions** to back large pages dynamically.

---

### 🧠 Performance Considerations

- On some machines, the **page table is loaded into hardware** on context switch.
  - Small pages → large page tables → **longer switch times**
  - Also consumes **more memory**

---

## 📊 Mathematical Optimization

---

Let:
- `s` = average process size (in bytes)  
- `p` = page size (in bytes)  
- `e` = page table entry size (in bytes)

### 🧮 Overhead Formula:
```
Total Overhead = (se / p) + (p / 2)
```

- **First term**: total page table size  
- **Second term**: internal fragmentation

> As `p` ↓ → page table grows  
> As `p` ↑ → fragmentation grows

---

### ✅ Optimum Page Size

Take derivative, set to 0:
```
d/dp (se/p + p/2) = –se/p² + 1/2 = 0  
⇒ p = √(2se)
```

#### 🔢 Example:
- `s = 1 MB`, `e = 8 bytes`  
→ `p ≈ 4 KB`

---

### 📌 Real-World Page Sizes

- Historically: **1 KB**
- Common now: **4 KB**
- Range: **512 bytes to 64 KB** (depending on architecture)
