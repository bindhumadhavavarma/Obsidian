
## ðŸ§© 3.5 Design Issues for Paging Systems

---

> Understanding paging mechanics isn't enoughâ€”like chess, **mastery requires strategy**. OS designers must consider key policies and trade-offs to ensure performance.

---

## ðŸ”€ 3.5.1 Local vs Global Allocation Policies

---

### ðŸ§  The Core Question

When a page fault occurs, **whose pages should we evict?**

---

### ðŸ—‚ï¸ Two Strategies

| Policy | Description | Example |
|--------|-------------|---------|
| **Local Replacement** | Replace a page **owned by the faulting process** only | Fig. 3-22(b): A6 replaces A5 |
| **Global Replacement** | Replace **any page** in memory, regardless of owner | Fig. 3-22(c): A6 replaces B3 |

---

### ðŸ“Š Trade-offs

- **Global**: Adapts to changing working set sizes; **better overall performance**.
- **Local**: Fixed allocation per process â†’ can lead to **thrashing** or **waste**.

> Global works well when processes have **variable memory demands**, but it requires active **monitoring and reallocation**.

---

### ðŸ§® Allocation Techniques

- **Equal Shares**: Divide available frames equally among processes.
- **Proportional Allocation**: Allocate based on process size.
- **Minimum Guarantee**: Ensure small processes can still run (e.g., instruction operands might span 6 pages).

---

### ðŸ“ˆ PFF â€“ Page Fault Frequency Algorithm

- **Goal**: Keep page fault rate within acceptable bounds.

#### ðŸ”„ Adjustment Logic:
- **Too many faults** (Line A, Fig. 3-23) â†’ **Increase** page frames.
- **Too few faults** (Line B) â†’ **Decrease** page frames.

> PFF **does not choose which page to evict**, just adjusts the **size of allocations**.

---

## ðŸš¦ 3.5.2 Load Control

---

### ðŸ’¥ Thrashing Despite Smart Allocation?

Even the best algorithms can't save the system if **total working sets > memory**.

---

### ðŸ§¹ Solutions

1. **ðŸ’€ OOM Killer (Out of Memory)**
   - Terminates processes with **high memory usage** or **low priority**.
   - Minimizes overall kills while freeing space.

2. **ðŸ’¾ Swapping Out**
   - Move full processes to disk temporarily.
   - Redistribute their frames to **active processes**.

3. **ðŸ“Š Two-Level Scheduling**
   - Some processes reside on disk, some run.
   - Scheduler juggles **who's in memory** to optimize throughput.

---

### ðŸ“‰ When Multiprogramming is Too Low

- Too few processes â†’ **CPU underutilized**.
- Must balance **paging load vs CPU usage**.

---

### âœ‚ï¸ Memory Reduction Techniques

- **ðŸ§¬ Deduplication (Same Page Merging)**:
  - Detect identical pages across processes.
  - Map both to a **single shared frame** (copy-on-write if modified).
  - Saves memory with **no performance loss**.

---

## ðŸ§¼ 3.5.3 Cleaning Policy

---

### ðŸ§½ The Problem

- All frames are **dirty and full**.
- Every page fault requires a **write before load**.

---

### ðŸ”„ Paging Daemon

A **background process** that:
- Sleeps most of the time.
- Wakes up to ensure **free, clean pages** are available.
- Writes dirty pages to disk **before** theyâ€™re needed.

---

### ðŸ•°ï¸ Two-Handed Clock

| Hand | Role |
|------|------|
| **Front Hand** | Controlled by paging daemon. Cleans dirty pages preemptively. |
| **Back Hand** | Handles actual page replacement on faults. |

> Ensures the **back hand hits clean pages**, improving performance.

Hereâ€™s the styled, structured, Obsidian-friendly summary for **Section 3.5.4 â€“ Page Size**:

## ðŸ“ 3.5.4 Page Size

---

### ðŸ§  OS Control Over Page Size

Even if the **hardware** uses, say, 4 KB pages, the **OS** can group them logically (e.g., pair two 4 KB pages to act as an 8 KB page). This offers flexibility but brings trade-offs.

---

## âš–ï¸ Trade-offs in Page Size

---

### ðŸ”» Arguments for **Small Pages**

#### 1. ðŸ§± Reduced Internal Fragmentation
- Processes rarely use a perfect multiple of the page size.
- **Half of the last page** is wasted on average â†’  
  Waste per process = `p/2`  
  Total for `n` segments = `n Ã— p/2`

#### 2. ðŸ§  Finer-Grained Memory Use
- Programs with **phased execution** benefit:
  - 4 KB phase â†’ needs only 4 KB if page = 4 KB
  - 32 KB page â†’ always needs full 32 KB in memory

> Small pages = less memory **waste per phase**

---

### ðŸ”º Arguments for **Large Pages**

#### 1. ðŸ§¾ Smaller Page Tables
- A 32 KB program needs:
  - 4 pages if page size = 8 KB
  - 64 pages if page size = 512 B

#### 2. ðŸš€ Disk I/O Efficiency
- Disk seeks dominate transfer time.
- 64 Ã— 512 B pages â†’ 640 ms  
- 4 Ã— 8 KB pages â†’ 48 ms  
> Large pages = **faster bulk transfers**

#### 3. ðŸ§  TLB Efficiency
- TLBs hold a **limited number** of entries.
- Fewer entries needed if each page is larger.
  - 1 MB memory, 4 KB pages â†’ 16 TLB entries
  - 2 MB pages â†’ 1 TLB entry
> Large pages reduce **TLB pressure**

---

### ðŸ§ª Mixed Page Sizes in Practice

- **Kernel**: large pages  
- **User processes**: small pages  
- **Transparent Huge Pages**: OS finds/creates **contiguous memory regions** to back large pages dynamically.

---

### ðŸ§  Performance Considerations

- On some machines, the **page table is loaded into hardware** on context switch.
  - Small pages â†’ large page tables â†’ **longer switch times**
  - Also consumes **more memory**

---

## ðŸ“Š Mathematical Optimization

---

Let:
- `s` = average process size (in bytes)  
- `p` = page size (in bytes)  
- `e` = page table entry size (in bytes)

### ðŸ§® Overhead Formula:
```
Total Overhead = (se / p) + (p / 2)
```

- **First term**: total page table size  
- **Second term**: internal fragmentation

> As `p` â†“ â†’ page table grows  
> As `p` â†‘ â†’ fragmentation grows

---

### âœ… Optimum Page Size

Take derivative, set to 0:
```
d/dp (se/p + p/2) = â€“se/pÂ² + 1/2 = 0  
â‡’ p = âˆš(2se)
```

#### ðŸ”¢ Example:
- `s = 1 MB`, `e = 8 bytes`  
â†’ `p â‰ˆ 4 KB`

---

### ðŸ“Œ Real-World Page Sizes

- Historically: **1 KB**
- Common now: **4 KB**
- Range: **512 bytes to 64 KB** (depending on architecture)
