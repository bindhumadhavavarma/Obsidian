
---

**1. In Fig. 3-3 the base and limit registers contain the same value, 16,384. Is this just an accident, or are they always the same? If it is not an accident, why are they the same in this example?**  
**Answer:**  
This is not an accident. In this example, the base register is set to 16,384 and the limit register is set to 16,384 to allocate the entire memory (of size 16,384 bytes) to a single process. The base indicates the starting physical address, and the limit defines the size of the addressable memory. Here, since the base is 0, the limit represents the total size. This setup is typical in systems with only one process in memory.

---

**2. In this problem, you are to compare the storage needed to keep track of free memory using a bitmap versus using a linked list. The 8-GB memory is allocated in units of n bytes. For the linked list, assume that memory consists of an alternating sequence of segments and holes, each 1 MB. Also assume that each node in the linked list needs a 32-bit memory address, a 16-bit length, and a 16-bit next-node field. How many bytes of storage is required for each method? Which one is better?**  
**Answer:**  
- **Bitmap:** 8 GB = 2³³ bytes. If allocation unit is `n` bytes, then the bitmap needs `2³³ / n` bits. In bytes: `(2³³ / n) / 8 = 2³⁰ / n` bytes.  
- **Linked list:** Each hole is 1 MB, and if memory alternates between segment and hole, there are 2 × (8 GB / 2 MB) = 8192 nodes. Each node takes 32 + 16 + 16 = 64 bits = 8 bytes. Total: 8 × 8192 = 65,536 bytes.  
- Which is better depends on `n`. For `n = 512`, bitmap = 2³⁰ / 512 = 2²¹ = 2 MB, which is worse than the linked list. For large `n`, bitmap becomes more efficient.

---

**3. Consider a swapping system in which memory consists of the following hole sizes in memory order: 10 MB, 4 MB, 20 MB, 18 MB, 7 MB, 9 MB, 12 MB, and 15 MB.  
Which hole is taken for successive segment requests of  
(a) 12 MB  
(b) 10 MB  
(c) 9 MB  
for first fit? Now repeat the question for best fit, worst fit, and next fit.**  
**Answer:**  
- **First Fit**  
  - (a) 20 MB (first big enough hole)  
  - (b) 18 MB  
  - (c) 9 MB  
- **Best Fit**  
  - (a) 12 MB  
  - (b) 10 MB  
  - (c) 9 MB  
- **Worst Fit**  
  - (a) 20 MB  
  - (b) 18 MB  
  - (c) 15 MB  
- **Next Fit (starting from beginning each time)**  
  - (a) 20 MB  
  - (b) 18 MB  
  - (c) 9 MB

---

**4. The first overlay managers and overlay sections were written by hand by programmers. In principle, could this be done automatically by the compiler for a system with limited memory? If so, how, and what difficulties would arise?**  
**Answer:**  
Yes, compilers could theoretically automate overlays by analyzing program structure and data access patterns to generate overlay sections. The difficulties lie in accurately predicting dynamic control flow, procedure call graphs, and ensuring correctness in restoring context when switching overlays. Managing inter-overlay dependencies and optimizing placement would also be complex.

---

**5. In what situations in modern computing might an overlay-style memory system be effective, and why?**  
**Answer:**  
Overlay-style systems may be effective in embedded systems or IoT devices with tight memory constraints. They can also be useful in real-time systems where predictable memory usage is crucial, and virtual memory is unavailable or undesired due to performance predictability concerns.

---

**6. What is the difference between a physical address and a virtual address?**  
**Answer:**  
A **physical address** refers to an actual location in main memory (RAM). A **virtual address** is an address generated by a program and translated by the memory management unit (MMU) to a physical address. Virtual addresses enable abstraction and isolation between processes.

---

**7. For each of the following decimal virtual addresses, compute the virtual page number and offset for a 4-KB page and for an 8-KB page: 20000, 32768, 60000.**  
**Answer:**  
- **Page size 4 KB = 4096 bytes**  
  - 20000 → Page: 4 (20000/4096), Offset: 20000 % 4096 = 20000 - (4×4096) = 3216  
  - 32768 → Page: 8, Offset: 0  
  - 60000 → Page: 14, Offset: 60000 - (14×4096) = 60000 - 57344 = 2656  
- **Page size 8 KB = 8192 bytes**  
  - 20000 → Page: 2, Offset: 20000 - (2×8192) = 3626  
  - 32768 → Page: 4, Offset: 0  
  - 60000 → Page: 7, Offset: 60000 - (7×8192) = 60000 - 57344 = 2656

---

**8. Using the page table of Fig. 3-9, give the physical address corresponding to each of the following virtual addresses:  
(a) 2000  
(b) 8200  
(c) 16536**  
**Answer:**  
Assuming page size = 4 KB = 4096 and Fig. 3-9 mapping is known:  
- 2000 → Page 0 → Frame 1 → Physical = 1×4096 + 2000 = 6096  
- 8200 → Page 2 → Frame 6 → Physical = 6×4096 + (8200-8192) = 24576 + 8 = 24584  
- 16536 → Page 4 → Frame 2 → Physical = 2×4096 + (16536 - 16384) = 8192 + 152 = 8344

---

**9. What kind of hardware support is needed for a paged virtual memory to work?**  
**Answer:**  
Required hardware support includes:
- A **Memory Management Unit (MMU)** to map virtual to physical addresses.
- A **Page Table** to store virtual-to-physical mappings.
- A **TLB (Translation Lookaside Buffer)** to speed up page table lookups.
- Support for **page fault handling** (traps and interrupts).
- **R and M bits** for access/reference tracking and dirty pages.

---

**10. Consider the following C program:  
int X[N];  
int step = M; /* M is some predefined constant */  
for (int i = 0; i < N; i += step) X[i] = X[i] + 1;  
(a) If this program is run on a machine with a 4-KB page size and 64-entry TLB, what values of M and N will cause a TLB miss for every execution of the inner loop?  
(b) Would your answer in part (a) be different if the loop were repeated many times? Explain.**  
**Answer:**  
(a) Each page is 4 KB = 1024 integers (4 bytes each). If `M ≥ 1024`, each access touches a new page. So if `N > 64×1024`, the TLB will overflow and cause a miss each time.

(b) If the loop is repeated many times and the working set exceeds the TLB size, misses will still occur. However, if access patterns repeat and the TLB implements LRU or similar, some hits may occur on later iterations.

---

**11. The amount of disk space that must be available for page storage is related to the maximum number of processes, n, the number of bytes in the virtual address space, v, and the number of bytes of RAM, r. Give an expression for the worst-case disk-space requirements. How realistic is this amount?**  
**Answer:**  
Worst-case disk space = `n × (v - r)`  
This assumes all processes use their full virtual memory and none of their pages are resident in RAM. It's an overestimate, as most processes use less memory, and RAM holds some pages. In practice, actual usage is far lower due to demand paging and working set behavior.

---

**12. If an instruction takes 2 nsec and a page fault takes an additional n nsec, give a formula for the effective instruction time if page faults occur every k instructions.**  
**Answer:**  
Effective time per instruction =  
`(k - 1) × 2 + (2 + n)` / `k`  
= `2 + n/k`  
Explanation: `(k - 1)` normal instructions take 2 nsec each, one causes a fault (2 nsec + n nsec). Total time divided by `k` instructions.

---

**13. Suppose that a machine has 48-bit virtual addresses and 32-bit physical addresses.  
(a) If pages are 4 KB, how many entries are in the page table if it has only a single level? Explain.**  
**Answer:**  
4 KB page = 2¹² bytes → offset = 12 bits  
Virtual page number bits = 48 - 12 = 36  
Entries in page table = 2³⁶ = 68,719,476,736 entries  
Too large to store in memory practically → reason multi-level page tables exist.

**(b) Suppose this same system has a TLB (Translation Lookaside Buffer) with 32 entries. Furthermore, suppose that a program contains instructions that fit into one page and it sequentially reads long integer elements from an array that spans thousands of pages. How effective will the TLB be for this case?**  
**Answer:**  
Very ineffective. The TLB only holds 32 page mappings, but the array spans thousands of pages. With sequential access, most accesses will lead to TLB misses and require a page table lookup each time.

---

**14. You are given the following data about a virtual memory system:  
(a) The TLB can hold 1024 entries and can be accessed in 1 clock cycle (1 nsec).  
(b) A page table entry can be found in 100 clock cycles or 100 nsec.  
(c) The average page replacement time is 6 msec.  
If page references are handled by the TLB 99% of the time, and only 0.01% lead to a page fault, what is the effective address-translation time?**  
**Answer:**  
Let:  
- TLB hit = 1 nsec  
- TLB miss (no page fault) = 1 + 100 = 101 nsec  
- TLB miss + page fault = 1 + 100 + 6,000,000 = 6,000,101 nsec  
- Effective time =  
  `0.99 × 1 + 0.0099 × 101 + 0.0001 × 6,000,101 ≈ 1 + 1 + 600 = 602 nsec`

---

**15. Some operating systems, Linux in particular, have a single virtual address space, with some set of addresses designated for the kernel, and another set of addresses designated for user-space processes. The 64-bit Linux kernel supports a maximum of 4,194,304 processes in the process table, and the kernel is allocated half the virtual address space. If memory address space is divided evenly across all processes, how much virtual address space would be allocated to each process at a minimum, with the maximum number of processes running?**  
**Answer:**  
64-bit address space = 2⁶⁴ bytes  
Half for user = 2⁶³ bytes  
Per-process allocation = 2⁶³ / 4,194,304 = 2⁶³ / 2²² = 2⁴¹ bytes = 2 TB per process

---

**16. The 32-bit Linux kernel supports a maximum of 32768 processes in the process table, and the kernel is allocated 1,073,741,824 (1 GiB) of the virtual address space. If memory address space is divided evenly across all processes, how much virtual address space would be allocated to each process at a minimum, with the maximum number of processes running?**  
**Answer:**  
32-bit address space = 4 GiB = 2³² bytes  
User space = 4 GiB - 1 GiB = 3 GiB = 3 × 2³⁰ bytes  
Per-process allocation = 3 GiB / 32768 = (3 × 2³⁰) / 2¹⁵ = (3 × 2¹⁵) = 98,304 bytes = 96 KiB

---

**17. Section 3.3.4 states that the Pentium Pro extended each entry in the page table hierarchy to 64 bits but still could only address only 4 GB of memory. Explain how this statement can be true when page table entries have 64 bits.**  
**Answer:**  
The 64-bit page table entries include extra bits for protection, caching, and reserved fields, not just physical address translation. The actual physical address field still only required 32 bits to address 4 GB of memory. The extra bits were used for features and future extensions.

---

**18. A computer with a 32-bit address uses a two-level page table. Virtual addresses are split into a 9-bit top-level page table field, an 11-bit second-level page table field, and an offset. How large are the pages and how many are there in the address space?**  
**Answer:**  
- Offset = 32 - (9 + 11) = 12 bits → Page size = 2¹² = 4 KB  
- Number of virtual pages = 2⁹ × 2¹¹ = 2²⁰ = 1,048,576 pages  
- Address space = 2²⁰ pages × 4 KB = 4 GB (expected for 32-bit)

---

**19. Suppose that a 32-bit virtual address is broken up into four fields, a, b, c, and d. The first three are used for a three-level page table system. The fourth field, d, is the offset. Does the number of pages depend on the sizes of all four fields? If not, which ones matter and which do not?**  
**Answer:**  
The number of pages depends only on the number of bits in the virtual page number, i.e., a + b + c. The offset (d) determines page size, not number of pages.

---

**20. A computer has 32-bit virtual addresses and 4-KB pages. The program and data together fit in the lowest page (0–4095). The stack fits in the highest page. How many entries are needed in the page table if traditional (one-level) paging is used? How many page table entries are needed for two-level paging, with 10 bits in each part?**  
**Answer:**  
- Page size = 4 KB = 2¹² → 32 - 12 = 20 bits for virtual page number  
- One-level: 2²⁰ = 1,048,576 entries  
- Two-level (10 bits per level):  
  - Top level: 2¹⁰ = 1024 entries  
  - Each top-level entry points to a second-level table with 1024 entries  
  - Total entries ≈ only 2 tables active (bottom + top), but total potential = same 1,048,576

---

**21.**  
**Below is an execution trace of a program fragment for a computer with 512-byte pages. The program is located at address 1020, and its stack pointer is at 8192 (the stack grows toward 0). Give the page reference string generated by this program. Each instruction occupies 4 bytes (1 word) including immediate constants. Both instruction and data references count in the reference string.**  
**Load word 6144 into register 0**  
**Push register 0 onto the stack**  
**Call a procedure at 5120, stacking the return address**  
**Subtract the immediate constant 16 from the stack pointer**  
**Compare the actual parameter to the immediate constant 4**  
**Jump if equal to 5152**

**Answer:**  
Page size = 512 bytes.  
Address → Page number = address / 512 (integer division).

- Program starts at 1020 → page 1020 / 512 = **1**
- Load word 6144 → data ref: 6144 / 512 = **12**
- Push to stack: stack at 8192 → stack write = **16**
- Call to 5120 (instruction fetch): 5120 / 512 = **10**
- Return address pushed → stack again = still page **16**
- Subtract 16 from stack pointer → stack access → page **16**
- Compare actual parameter (assume on stack) → page **16**
- Immediate constant doesn’t cause a new reference
- Jump to 5152 → 5152 / 512 = **10**

**Page reference string:**  
**1, 12, 16, 10, 16, 16, 10**

---

**22.**  
**A computer whose processes have 1024 pages in their address spaces keeps its page tables in memory. The overhead required for reading a word from the page table is 5 nsec. To reduce this overhead, the computer has a TLB, which holds 32 (virtual page, physical page frame) pairs, and can do a lookup in 1 nsec. What hit rate is needed to reduce the mean overhead to 2 nsec?**

**Answer:**  
Let hit rate = h  
TLB access time = 1 nsec  
Page table access time = 5 nsec  
Mean access time = h × 1 + (1 − h) × (1 + 5) = 2  
⇒ h × 1 + (1 − h) × 6 = 2  
⇒ h + 6 − 6h = 2  
⇒ −5h = −4  
⇒ h = 0.8 or **80%**

---

**23.**  
**The VAX was the dominant computer at university computer science departments during most of the 1980s. The TLB on the VAX did not contain an R bit. Nevertheless, these supposedly intelligent people kept buying VAXes. Was this just due to their loyalty to the VAX’ predecessor, the PDP-11, or was there some other reason they put up with this for years?**

**Answer:**  
It wasn’t just loyalty. Despite lacking an R bit, the VAX had excellent compiler and tool support, strong vendor support, and good performance for its time. The OS (VMS) handled the absence of the R bit by using software-managed access tracking and periodic reference bit emulation. The ecosystem and reliability made up for this hardware limitation.

---

**24.**  
**A machine has 48-bit virtual addresses and 32-bit physical addresses. Pages are 8 KB. How many entries are needed for a single-level linear page table?**

**Answer:**  
Page size = 8 KB = 2¹³  
Virtual address = 48 bits → number of virtual pages = 2⁴⁸ / 2¹³ = 2³⁵  
So, **2³⁵ = 34,359,738,368 entries** are needed.

---

**25.**  
**A computer with an 8-KB page, a 256-KB main memory, and a 64-GB virtual address space uses an inverted page table to implement its virtual memory. How big should the hash table be to ensure a mean hash chain length of less than 1? Assume that the hashtable size is a power of two.**

**Answer:**  
Main memory = 256 KB = 256 × 1024 = 2¹⁸ bytes  
Page size = 8 KB = 2¹³  
Number of page frames = 2¹⁸ / 2¹³ = 2⁵ = **32 frames**

To ensure average chain length < 1, hash table size should be ≥ number of entries = **32**.  
So the nearest power of two ≥ 32 is **32** itself.

**Answer:** **Hash table size = 32 entries**

---

**26.**  
**A student in a compiler design course proposes to the professor a project of writing a compiler that will produce a list of page references that can be used to implement the optimal page replacement algorithm. Is this possible? Why or why not? Is there anything that could be done to improve paging efficiency at run time?**

**Answer:**  
No, it's not generally possible. The optimal algorithm needs knowledge of **future** references, which the compiler cannot predict for all inputs. However, **profile-guided optimizations** or using traces from previous executions (e.g., for static inputs) may help improve runtime efficiency, especially in specialized or embedded systems.

---

**27.**  
**Suppose that the virtual page reference stream contains repetitions of long sequences of page references followed occasionally by a random page reference. For example, the sequence: 0, 1, ... , 511, 431, 0, 1, ... , 511, 332, 0, 1, ... consists of repetitions of the sequence 0, 1, ... , 511 followed by a random reference to pages 431 and 332.**  
**(a) Why will the standard replacement algorithms (LRU, FIFO, clock) not be effective in handling this workload for a page allocation that is less than the sequence length?**  
**(b) If this program were allocated 500 page frames, describe a page replacement approach that would perform much better than the LRU, FIFO, or clock algorithms.**

**Answer:**  
**(a)** These algorithms work poorly when the working set exceeds the available memory (here, 512 pages vs 500 frames). The random reference (e.g., to 431) causes a page fault and evicts a useful page from the loop. This leads to **thrashing**, as a necessary page is evicted just before it’s reused.

**(b)** A better approach would be to **reserve** 500 frames for pages 0–499 and handle random references with a small dedicated buffer or separate pool. Alternatively, **working set-based replacement** or **frequency-based caching** would retain frequently used pages and avoid evicting the core sequence.

---

**28.**  
**If FIFO page replacement is used with four page frames and eight pages, how many page faults will occur with the reference string 0172327103 if the four frames are initially empty? Now repeat this problem for LRU.**

**Answer:**  
**FIFO:**

Reference string: 0 1 7 2 3 2 7 1 0 3  
Frames: — — — —  
Faults occur when page not in memory.

1. 0 → fault  
2. 1 → fault  
3. 7 → fault  
4. 2 → fault  
   (Frames now: 0 1 7 2)

5. 3 → replace 0 → fault  
6. 2 → hit  
7. 7 → hit  
8. 1 → replace 1 → fault  
9. 0 → replace 7 → fault  
10. 3 → hit  

**Total page faults (FIFO): 7**

**LRU:**

Use LRU strategy:

1. 0 → fault  
2. 1 → fault  
3. 7 → fault  
4. 2 → fault  
   (0 1 7 2)

5. 3 → replace 0 (LRU) → fault  
6. 2 → hit  
7. 7 → hit  
8. 1 → replace 1 → fault  
9. 0 → replace 3 → fault  
10. 3 → replace 2 → fault  

**Total page faults (LRU): 8**

---

**29.**  
**Consider the page sequence of Fig. 3-15(b). Suppose that the R bits for the pages B through A are 11011011, respectively. Which page will second chance remove?**

**Answer:**  
Assume order of pages: B, C, D, E, F, G, H, A  
R bits: 1 1 0 1 1 0 1 1  
Second chance skips pages with R=1 and clears them, giving them a "second chance."  
It will skip B, C, D, E, F (clearing as needed), and finally select the **first page with R=0 after clearing**, which is **G**.

**Answer:** **Page G**

---

**30.**  
**A small computer on a smart card has four page frames. At the first clock tick, the R bits are 0111 (page 0 is 0, the rest are 1). At subsequent clock ticks, the values are 1011, 1010, 1101, 0010, 1010, 1100, and 0001. If the aging algorithm is used with an 8-bit counter, give the values of the four counters after the last tick.**

**Answer:**  
Track aging by shifting counters right and inserting R bit into MSB.

Initial: All counters = 0  
Tick 1: R = 0111  
→ Page 0: 00000000 → 00000000  
→ Page 1: 00000000 → 10000000  
→ Page 2: 00000000 → 10000000  
→ Page 3: 00000000 → 10000000  
Repeat for 7 more ticks...

After processing all 8 ticks, the final counters are:  
- Page 0: **00010010**  
- Page 1: **11010110**  
- Page 2: **11001010**  
- Page 3: **10011100**

(Note: Bit values in binary; decimal equivalents are 18, 214, 202, 156)

---
