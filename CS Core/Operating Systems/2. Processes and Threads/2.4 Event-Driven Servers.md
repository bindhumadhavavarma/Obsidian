In the previous section, we have seen two possible designs for a Web server: a
fast multithreaded one and a slow single-threaded one. Suppose that threads are not
available or not desirable but the system designers find the performance loss due to
single threading, as described so far, unacceptable. If nonblocking versions of system
calls, such as read, are available, a third approach is possible. When a request
comes in, the one and only thread examines it. If it can be satisfied from the cache,
fine, but if not, a nonblocking disk operation is started.
The server records the state of the current request in a table and then goes and
gets the next event. The next event may either be a request for new work or a reply
from the disk about a previous operation. If it is new work, that work is started. If
it is a reply from the disk, the relevant information is fetched from the table and the
reply processed. With nonblocking disk I/O, a reply probably will have to take the
form of a signal or interrupt.

### **Event-Driven Servers**

In **traditional Web servers**, we typically see:

1. **Single-threaded servers** → Simple but **slow**, as they block on I/O.
2. **Multi-threaded servers** → Faster but introduce **overhead** from thread creation and management.

If **threads are unavailable** or **not desirable**, an alternative is to use **event-driven servers**, which use **nonblocking system calls** to avoid performance loss.

---
### **How Event-Driven Servers Work**

1. **Request Handling:**
    
    - When a **request** arrives, the **server checks the cache**.
    - If the data is cached, the response is sent immediately.
    - If **not cached**, a **nonblocking disk I/O** operation is started.
2. **State Tracking:**
    
    - Instead of waiting (blocking), the server **records the request state** in a table.
    - The server **moves to handle other requests** while waiting for disk I/O.
    - When the I/O completes, the server **retrieves the state from the table** and processes the response.
3. **Event-Driven Execution:**
    
    - The server **never blocks** and **always works on available events**.
    - Uses **signals or interrupts** to notify when I/O completes.
    - Implemented using a **finite-state machine (FSM)**, where the **state updates based on events**.

---

### **Advantages of Event-Driven Programming**

- **Higher performance** (no blocking, minimal context switching).
- **Efficient memory usage** (no need for multiple threads or stacks).
- **Scalability** (handles thousands of connections efficiently).

Popular event-driven Web servers:

- **nginx**
- **Node.js** (event loop model)

Operating systems provide **optimized event-driven APIs** like:

- **epoll** (Linux)
- **kqueue** (FreeBSD)
- **I/O Completion Ports (Windows)**

These **allow monitoring multiple network connections** without blocking.

---

### **Comparison: Threaded vs. Event-Driven Servers**

|**Model**|**Characteristics**|
|---|---|
|**Threads**|Parallel execution, blocking system calls.|
|**Single-threaded**|Simple but slow, blocks on I/O.|
|**Event-driven (FSM)**|Parallel execution, nonblocking calls, uses interrupts.|

---

### **Key Takeaways**

- Event-driven servers **simulate multithreading** without threads.
- The **finite-state machine (FSM) model** ensures **high efficiency**.
- **Web servers and OS kernels** often use event-driven programming for **high throughput (C10k problem)**.

