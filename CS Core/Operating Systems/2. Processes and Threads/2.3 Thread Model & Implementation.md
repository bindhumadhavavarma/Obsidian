### **Threads and the Process Model**

The process model consists of two independent concepts: **resource grouping** and **execution**. Threads introduce the ability to separate execution from resource grouping, allowing multiple threads to run within a single process.

### **Threads vs. Processes**

- A **process** is a collection of resources, including memory, files, and system attributes.
- A **thread** is an independent execution unit within a process, containing its own **program counter, registers, and stack** but sharing the process’s address space and resources.
- Unlike processes, **threads are not completely isolated** from each other. They can read and modify shared memory, making inter-thread communication more efficient but also introducing synchronization challenges.

### **Multithreading and CPU Execution**

- The CPU rapidly switches between threads, giving the illusion of parallel execution.
- Unlike processes, threads within a process are not independent—they share memory, global variables, and other resources, leading to potential data corruption if not properly synchronized.

### **Thread States and Execution Flow**

Threads, like processes, can be in the following states:

1. **Running** – Actively executing on the CPU.
2. **Blocked** – Waiting for an event (e.g., I/O completion).
3. **Ready** – Waiting to be scheduled on the CPU.
4. **Terminated** – Completed execution or forcefully stopped.

Transitions between these states mirror the process state transitions, but **threads within a process share resources**, whereas processes operate independently.

### **Thread Stacks and Execution Flow**

Each thread has its **own stack**, containing:

- Local variables.
- Return addresses for function calls.
- Execution history for tracking active procedures.

This separation is necessary because different threads may execute different procedures within the same process.

### **Thread Management and Challenges**

- **Thread Yielding**: Since threads don’t have hardware-enforced scheduling like processes (no clock interrupts), they should voluntarily **yield** CPU time to other threads to ensure fair execution.
- **Thread Synchronization**: Problems arise when multiple threads access shared resources. Examples include:
    - One thread closing a file while another is still reading.
    - Two threads detecting low memory and attempting to allocate additional memory simultaneously, causing redundant allocation.

### **Threads and Process Forking**

- Forking a **single-threaded process** is straightforward, as the child process gets a copy of the parent’s resources.
- Forking a **multithreaded process** creates **only one thread** in the child by default.
    - In **Linux**, `pthread_atfork()` allows registering fork handlers to manage additional threads post-fork.
    - Different OS implementations handle this differently, making thread forking a complex design decision.

### **Key Takeaways**

- Threads **share** memory and resources within a process, unlike independent processes.
- They improve **performance** by avoiding process creation overhead and enabling concurrent execution within a process.
- However, **synchronization issues** must be carefully managed to prevent data corruption.
- **Forking multithreaded processes** requires special handling to ensure proper thread management in the child process.

---
### **POSIX Threads (Pthreads)**

IEEE defines a standard for threads called **POSIX Threads (Pthreads)**. Below is a table of common **Pthreads** functions and their descriptions.

|**Thread Call**|**Description**|
|---|---|
|`pthread_create`|Create a new thread|
|`pthread_exit`|Terminate the calling thread|
|`pthread_join`|Wait for a specific thread to exit|
|`pthread_yield`|Release the CPU to let another thread run|
|`pthread_attr_init`|Create and initialize a thread’s attribute structure|
|`pthread_attr_destroy`|Remove a thread’s attribute structure|

### **Thread Properties and Usage**

- Each **Pthread** has an **identifier**, a **set of registers**, and an **attribute structure** (defining stack size, scheduling parameters, etc.).
- **Thread Creation:** A new thread is created using `pthread_create()`, which returns the thread identifier (similar to process IDs).
- **Thread Termination:** A thread terminates by calling `pthread_exit()`, which stops execution and releases its stack.
- **Yielding CPU:** A thread can voluntarily yield control using `pthread_yield()`, allowing another thread to execute.
- **Thread Attributes:**
    - `pthread_attr_init()` initializes an attribute structure.
    - `pthread_attr_destroy()` frees up memory allocated for a thread's attributes.

### **Example Usage**

- A **main program** can create multiple threads in a loop using `pthread_create()`.
- Each thread runs independently and may execute in **different orders** due to scheduling.
- `pthread_join()` allows a thread to wait for another to complete before proceeding.

**Note:** These are just the basic **Pthreads** functions. Additional calls exist for thread synchronization, which will be covered later.

---
### **Implementing Threads in User Space**

Threads can be implemented in **user space** or **kernel space**, each with its own trade-offs. A hybrid approach is also possible.

### **User-Level Threads**

- In this model, the **kernel is unaware of threads** and only manages single-threaded processes.
- The threading functionality is provided by a **user-space library**, which maintains a **thread table** for each process, tracking thread states, program counters, stack pointers, and registers.
- Thread switching is handled within **user space**, making it significantly faster than kernel-level threads since no kernel trap or context switch is needed.

### **Advantages of User-Level Threads**

1. **Portable & OS-Independent** – Can run on any operating system without native thread support.
2. **Fast Context Switching** – No need to switch to kernel mode, making thread scheduling and switching extremely efficient.
3. **Custom Scheduling** – A process can implement its own thread scheduling algorithm, beneficial for certain applications like garbage collection.
4. **Scalability** – Unlike kernel threads, user threads do not require kernel resources, allowing thousands of threads to exist without burdening the system.

### **Disadvantages of User-Level Threads**

1. **Blocking System Calls** – If a thread makes a blocking system call (e.g., reading from a keyboard), the **entire process gets blocked**, halting all other threads because the OS doesn't even know that this process is multithreaded.
    - Workarounds like **non-blocking system calls** or `select()` exist but are inefficient and require modifying the OS library.
2. **Page Faults Block All Threads** – If one thread triggers a **page fault**, the entire process is suspended, even if other threads are runnable (again because the OS doesn't know what a thread is since all the implementation is in User Level).
3. **No Preemptive Scheduling** – Since the **OS is unaware of threads**, it cannot preempt them.
    - If a thread enters an infinite loop, **no other thread will execute unless it voluntarily yields the CPU**.
    - The runtime system can request periodic interrupts (e.g., every second), but this is inefficient.
4. **Limited Use Cases** – User threads are **not useful for applications that frequently interact with the OS** (e.g., web servers), as they require constant system calls, defeating the purpose of user-space management.

### **Summary**

- User-space threads provide high performance and flexibility but suffer from **blocking issues and lack of OS integration**.
- They work best for **compute-heavy tasks with minimal I/O** but are not ideal for **I/O-bound applications** where kernel threads are more efficient.
- Modern systems often prefer **kernel-level or hybrid threading models** for better efficiency and reliability.

---
### **Implementing Threads in the Kernel**

When threads are managed by the **kernel**, there is no need for a separate **run-time system** or **thread table** in each process. Instead, the **kernel maintains a global thread table** that keeps track of all threads in the system.

### **Kernel Thread Management**

- **Thread Creation & Destruction:** Managed through **kernel calls**, unlike user-level threads, which use a run-time system.
- **Kernel Thread Table:** Stores **each thread’s state, registers, and scheduling information**.
- **Blocking Operations:** Since all blocking calls are system calls, the kernel can schedule another thread **from the same process or another process**.

### **Advantages of Kernel Threads**

1. **No Non-Blocking System Calls Needed:** Unlike user-space threads, which require special non-blocking system calls, kernel threads use regular system calls.
2. **Better CPU Utilization:** If a thread causes a **page fault**, the kernel can run another thread in the same process while waiting for disk I/O.
3. **True Multithreading Across CPUs:** Threads from the same process can run **simultaneously on multiple CPUs**, which is not possible with pure user-space threads.

### **Disadvantages of Kernel Threads**

4. **Higher Overhead:** Thread creation, termination, and context switching require **costly system calls**, leading to **higher CPU overhead**.
5. **Thread Recycling to Reduce Cost:** Some systems mark terminated threads as **inactive instead of fully destroying them**, allowing them to be reused to save overhead.
6. **Thread Handling in Fork Calls:**
    - If a **process forks**, should the child inherit all threads or just one?
    - If `exec` is called immediately after forking, keeping **only one thread** makes sense.
    - If the child continues execution, **retaining all threads** is preferable.

### **Handling Signals in Multithreaded Processes**

- Traditionally, **signals** are sent to **processes, not individual threads**.
- In Linux, a signal may be **handled by any thread** chosen by the OS, unless explicitly blocked in some threads.
- A possible approach is allowing threads to **register interest** in specific signals, so only interested threads handle them.

### **Key Takeaway**

While **kernel threads solve issues like blocking and true parallel execution**, they come at the cost of **higher system call overhead and additional complexity** in thread management, such as handling **signals and fork calls**.

---

### **Hybrid Thread Implementations**

Hybrid thread implementations aim to **combine the advantages of both user-level and kernel-level threads**. One approach is to use **kernel threads** but **multiplex** multiple user-level threads onto each kernel thread, as shown in the figure below.

#### **Hybrid Thread Model**

- The **kernel only manages kernel threads**, not user-level threads.
- Each **kernel thread** runs **multiple user threads**, which are scheduled by a **user-space thread manager**.
- The programmer can **control how many kernel threads** are used and **how many user threads** run on each.
- This provides **flexibility**, allowing fine-grained control over **performance and resource usage**.

---

### **Making Single-Threaded Code Multithreaded**

Converting **single-threaded** programs to **multithreaded** ones is **complex** due to shared memory, global variables, and non-reentrant libraries.

#### **Challenges & Solutions**

1. **Global Variable Conflicts**
    
    - Example: The **errno** variable in UNIX is a global error status variable. If two threads use it simultaneously, it can **overwrite each other’s errors**.
    - **Solution:** Assign **each thread its own private global variables**. This creates an **additional scoping level** between local variables (within functions) and global variables (shared across processes).
2. **Thread-Specific Global Variables**
    
    - Programming languages don’t have built-in support for **thread-private global variables**.
    - **Solution:** Create a **thread-local storage system** where each thread gets its own copy of global variables.
    - Example:
        - `create_global("bufptr")` → Allocates a unique global variable per thread.
        - `set_global("bufptr", &buf)` → Stores data for the current thread.
        - `bufptr = read_global("bufptr")` → Retrieves the thread-specific value.
3. **Non-Reentrant Libraries**
    
    - Some libraries **use shared buffers or static memory**, making them unsafe for multiple threads.
    - Example: A **network send function** may store messages in a **shared buffer** before sending. If **another thread interrupts and modifies the buffer**, it causes **data corruption**.
    - **Solution:**
        - **Rewrite libraries** to use **thread-local storage** instead of shared buffers.
        - Use **locks** to prevent simultaneous access but **reduces parallelism**.
4. **Memory Allocation Issues**
    
    - **malloc/free** manage **shared memory** and may temporarily **leave memory structures in an inconsistent state** during an update.
    - If a **thread switch** happens mid-update, **another thread may use corrupt memory**.
    - **Solution:**
        - Use **thread-safe memory allocators**.
        - Use **mutex locks** to ensure safe access, but this **reduces performance**.
5. **Signal Handling in Multithreading**
    
    - **Thread-Specific Signals:** If a **thread** sets an **alarm**, it should receive the signal. But **user-level threads are invisible to the kernel**, so it cannot directly deliver signals to the correct thread.
    - **Process-Wide Signals:** A **CTRL-C** event affects all threads. But what if **one thread wants to catch it while another expects it to terminate the process**?
    - **Solution:** Define **thread-specific signal handlers** and let threads **register interest** in signals.
6. **Stack Management Issues**
    
    - In single-threaded systems, **if a process stack overflows**, the kernel **automatically expands it**.
    - In multithreading, **each thread has its own stack**, but the kernel **may not recognize individual thread stacks**.
    - **Solution:**
        - Use **guard pages** to detect stack overflows early.
        - Have **the kernel explicitly manage multiple stacks per process**.

---

### **Key Takeaways**

- Hybrid threading **combines the best of user-level and kernel threads**, providing **flexibility** while **avoiding blocking issues**.
- **Converting single-threaded applications to multithreaded ones is difficult** due to **global variable conflicts, non-reentrant libraries, signal handling issues, and memory management problems**.
- **Thread-local storage** and **mutex locks** help prevent conflicts, but they **can impact performance**
- **Library and system calls may need modifications** to be **fully thread-safe**, requiring **substantial system redesign**.

