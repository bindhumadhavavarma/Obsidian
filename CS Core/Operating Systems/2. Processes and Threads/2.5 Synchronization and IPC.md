### **Synchronization and Interprocess Communication (IPC)**

Processes often need to **communicate and synchronize** to ensure correct execution. IPC is essential for:

1. **Passing Information** → E.g., a shell pipeline where output from one process is input to another.
2. **Mutual Exclusion** → Preventing race conditions when multiple processes modify shared data.
3. **Synchronization** → Ensuring correct sequencing of dependent tasks.

These issues also apply to **threads**, as they share memory within a process.

---

## **2.4.1 Race Conditions**

A **race condition** occurs when multiple processes or threads access shared data **without proper synchronization**, leading to unpredictable results.

Example:

- Consider a **print spooler** where multiple processes add files to a shared queue.
- Two processes, **A and B**, attempt to update the queue **simultaneously**.
- If they read and write the **same memory location** without synchronization, one update may overwrite the other, **causing lost data**.

Race conditions are hard to detect since they **occur sporadically**, depending on the exact timing of execution.

---

## **2.4.2 Critical Regions**

A **critical region (or critical section)** is the part of the code where a process accesses shared data. **Mutual exclusion** ensures that **only one process** enters its critical section at a time.

**Four conditions for proper synchronization:**

4. **Mutual exclusion** → No two processes can be in their critical section simultaneously.
5. **Independence from CPU speed** → The solution should work regardless of how fast each process runs.
6. **No unnecessary blocking** → A process **outside** its critical section must not prevent another process from entering.
7. **No starvation** → No process should wait **forever** to enter its critical section.

If these conditions hold, race conditions are prevented.

---

## **2.4.3 Mutual Exclusion with Busy Waiting**

### **1. Disabling Interrupts**

- A **single-threaded** CPU can **disable interrupts** while accessing shared memory, preventing context switches.
- **Problem:** Not feasible for user processes since a **malfunctioning process could disable interrupts permanently**, **crashing** the system.
- **Not effective in multiprocessor systems**, since disabling interrupts on one CPU does not prevent interference from another CPU.

### **2. Lock Variables**

- A shared **lock variable** (0 = free, 1 = occupied) can be used to enforce mutual exclusion.
- **Problem:** A race condition can still occur if two processes check and update the lock **simultaneously**.

### **3. Strict Alternation**

- A **turn variable** ensures processes take turns.
- **Problem:** If one process is much slower, the faster one **waits unnecessarily**, violating the **no unnecessary blocking** rule.

---
### **Peterson’s Solution**

Peterson’s algorithm is a software-based solution to the **mutual exclusion** problem that avoids strict alternation and improves upon Dekker’s algorithm. It ensures that two processes do not enter their **critical regions** simultaneously.

![[Pasted image 20250203222755.png]]
#### Working of Peterson’s Solution:

1. Each process calls `enter_region(process_number)` before accessing the shared resource.
2. A process **indicates interest** in entering the critical region by setting its corresponding `interested` array element to `TRUE`.
3. The **turn** variable is used to give priority to one process in case of contention.
4. If the **other process is also interested**, the process waits in a loop until the turn favors it.
5. When finished, the process calls `leave_region(process_number)`, setting its `interested` flag to `FALSE`, allowing the other process to proceed.

#### Example Execution:

- **Case 1**: If **only one process** wants access, it proceeds immediately.
- **Case 2**: If **both processes try at the same time**, the one that **sets `turn` last** will wait, ensuring mutual exclusion.

This solution satisfies all four conditions for correct **critical section handling**:

6. **Mutual Exclusion** - No two processes enter the critical region simultaneously.
7. **Progress** - If no process is in the critical region, another process will not be unnecessarily blocked.
8. **Bounded Waiting** - Each process gets a turn without indefinite blocking.
9. **Independence from Speed** - The solution works without assumptions about execution speed or number of CPUs.

Peterson’s algorithm is **efficient** and **works well in theory**, but is not widely used in modern multi-core systems due to **hardware-level optimizations** (like atomic operations) being more effective for concurrency control.

---

### **The TSL (Test and Set Lock) Instruction**

To implement **mutual exclusion** in multiprocessor systems, hardware support is needed. Some processors provide an atomic instruction called **Test and Set Lock (TSL)**, which helps coordinate access to shared resources.

![[{E21357DB-9C3D-4B48-A35D-096FAA92036B}.png]]
#### **How TSL Works:**

- **TSL RX,LOCK**:
    - Reads the value of `LOCK` into register `RX`.
    - Sets `LOCK` to **1** atomically.
    - Prevents any other processor from accessing the memory until the instruction completes.

This atomicity ensures that **no two processes can enter their critical regions simultaneously**, avoiding race conditions.

#### **How TSL Prevents Race Conditions:**

- A shared variable `LOCK` is used.
- A process checks `LOCK`. If `0`, it sets it to `1` (locking the resource) and enters the **critical section**.
- Once done, it resets `LOCK` to `0`, allowing other processes to proceed.

#### **Implementation Using TSL**

- **Entering the Critical Region**:
    - Continuously check `LOCK` using **busy waiting**.
    - Once `LOCK == 0`, acquire the lock.
- **Leaving the Critical Region**:
    - Set `LOCK = 0`, releasing access.

This approach requires **cooperation between processes**. If a process does not properly release the lock, mutual exclusion fails.

---

### **The XCHG (Exchange) Instruction**

An alternative **atomic instruction** for synchronization is **XCHG**:

- **XCHG swaps** the contents of a register and a memory word **atomically**.
- Used in **Intel x86 processors** for **low-level synchronization**.
![[{10F224C1-E1A9-4BB9-AC0A-616D5DC96A11}.png]]
#### **How XCHG Works:**

- Instead of **TSL**, the process swaps a register value (`1` for locking) with `LOCK`.
- If the previous value was `0`, it means the lock was free, and the process can proceed.
- Otherwise, it keeps checking (`busy waiting`) until it acquires the lock.

Both **TSL** and **XCHG** are widely used for implementing **low-level locking mechanisms** in **multiprocessor environments** to **prevent race conditions** efficiently.

---

### **Sleep and Wakeup Mechanism**

Peterson’s solution and hardware-based approaches like **TSL (Test and Set Lock) or XCHG** are correct but rely on **busy waiting**, which wastes CPU cycles and can lead to **priority inversion** issues. A better approach is **blocking mechanisms**, such as **sleep and wakeup**, to handle process synchronization efficiently.

---

### **Producer-Consumer Problem (Bounded-Buffer Problem)**

The **producer-consumer problem** (or bounded-buffer problem) illustrates the need for **process synchronization**. Two processes share a fixed-size buffer:

- The **producer** generates data and places it into the buffer.
- The **consumer** retrieves data from the buffer for processing.

#### **Problems That Arise**

1. **Buffer Overflow:** The producer must not add data if the buffer is full.
2. **Buffer Underflow:** The consumer must not remove data if the buffer is empty.
3. **Race Conditions:** If both processes access the buffer counter `count` simultaneously, **inconsistent** results may occur.

#### **Solution Using Sleep and Wakeup**

- **Sleep:** A process that cannot proceed (due to buffer overflow or underflow) **blocks** itself instead of busy waiting.
- **Wakeup:** The other process **notifies** the sleeping process when it can continue.

#### **Race Condition in Sleep and Wakeup**

A critical race condition occurs when:

4. The **consumer** checks `count` and sees it as `0`, meaning the buffer is empty.
5. Before it goes to **sleep**, the scheduler switches to the **producer**.
6. The **producer** inserts an item, **increments `count`**, and calls **wakeup**.
7. But since the **consumer is not yet sleeping**, the wakeup signal is **lost**.
8. When the consumer finally goes to sleep, it **never wakes up**, leading to **deadlock**.

---

### **Possible Fix: Wakeup-Waiting Bit**

To avoid losing wakeup signals:

- Introduce a **wakeup-waiting bit**.
- If a process is **not yet sleeping** when wakeup is sent, this bit is set.
- When the process tries to sleep, it first checks this bit. If set, it **stays awake** and clears the bit.

However, for **multiple processes**, a **single wakeup-waiting bit is not enough**, and more sophisticated **synchronization primitives** (like semaphores and monitors) are required.

This sets the foundation for **more advanced process synchronization mechanisms**, which we will explore next.

---

### **Semaphores**

In 1965, **E. W. Dijkstra** introduced **semaphores** as a synchronization tool to solve the lost wakeup problem and race conditions. Semaphores act as **integer counters** that regulate access to shared resources in concurrent programming.

---

### **Definition of Semaphores**

A **semaphore** is an integer variable that:

- Can be **incremented** (using `up`) to indicate a resource is available.
- Can be **decremented** (using `down`) to indicate a resource is occupied.
- If a process tries to decrement a semaphore that is **zero**, it **blocks** until another process increments it.

Operations on semaphores are **atomic**, meaning they **cannot be interrupted** in between execution.

#### **Types of Semaphores**

1. **Binary Semaphores (Mutex Locks)** – Only **0 or 1** values, ensuring **mutual exclusion** (one process at a time).
2. **Counting Semaphores** – Can hold values greater than 1, used for **resource synchronization**.

---

### **Operations on Semaphores**

|**Semaphore Operation**|**Description**|
|---|---|
|`down(sem)` (P operation)|Decreases semaphore value by 1. If it is 0, the process **blocks** until it becomes greater than 0.|
|`up(sem)` (V operation)|Increases semaphore value by 1. If any process is waiting, it **wakes up** one of them.|

> **Note:** The original names were `P()` and `V()`, derived from **Dutch** words "Proberen" (try) and "Verhogen" (increase), but `down()` and `up()` are now widely used.

---

### **Solving the Producer-Consumer Problem Using Semaphores**

The **Producer-Consumer** (Bounded Buffer) problem involves:

- A **producer** creating items and storing them in a **shared buffer**.
- A **consumer** retrieving items from the **buffer**.

To ensure proper synchronization:

1. **`mutex`** ensures **only one process** (producer or consumer) accesses the buffer at a time.
2. **`empty`** counts the **available empty slots** in the buffer.
3. **`full`** counts the **filled slots** in the buffer.

#### **Semaphore Initialization**

|**Semaphore**|**Purpose**|**Initial Value**|
|---|---|---|
|`mutex`|Ensures **mutual exclusion**|`1`|
|`empty`|Keeps track of **available buffer slots**|`N` (buffer size)|
|`full`|Keeps track of **occupied slots**|`0`|

#### **Producer Process**

4. Waits if `empty` is `0` (buffer full) → **`down(empty)`**
5. Locks the buffer → **`down(mutex)`**
6. Produces item and stores it
7. Unlocks the buffer → **`up(mutex)`**
8. Signals consumer that data is available → **`up(full)`**

#### **Consumer Process**

9. Waits if `full` is `0` (buffer empty) → **`down(full)`**
10. Locks the buffer → **`down(mutex)`**
11. Retrieves item from buffer
12. Unlocks the buffer → **`up(mutex)`**
13. Signals producer that space is available → **`up(empty)`**

---

### **Semaphores for Synchronization and Mutual Exclusion**

- **Mutex (`mutex`)** – Ensures **one process at a time** accesses the buffer.
- **Synchronization (`full` & `empty`)** – Ensures **correct execution order**.

Without semaphores, processes might **overwrite each other's work** or **miss wakeup signals**, leading to **race conditions and deadlocks**.

Semaphores provide **efficient process synchronization**, making them fundamental in **operating systems, databases, and concurrent applications**.

